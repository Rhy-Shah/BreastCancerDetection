{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ab9742-190b-465d-9e13-d7a04dc91617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291dd5b9",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3063b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737305884.769628  133784 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737305884.773619  133784 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "class_name = { 0: 'Mass',\n",
    "1: 'Spiculation',\n",
    "2: 'Suspicious Calcification',\n",
    "3: 'Architectural Distortion',\n",
    "4: 'Asymmetry',\n",
    "5: 'Focal Asymmetry',\n",
    "6: 'Skin Thickening',\n",
    "7: 'Global Asymmetry',\n",
    "8: 'Suspicious Lymph Node',\n",
    "9: 'Skin Retraction',\n",
    "10: 'Nipple Retraction'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    0: (255, 0, 0),      # Red\n",
    "    1: (0, 255, 0),      # Green\n",
    "    2: (0, 0, 255),      # Blue\n",
    "    3: (255, 255, 0),    # Yellow\n",
    "    4: (255, 165, 0),    # Orange\n",
    "    5: (128, 0, 128),    # Purple\n",
    "    6: (0, 255, 255),    # Cyan\n",
    "    7: (255, 192, 203),  # Pink\n",
    "    8: (128, 128, 0),    # Olive\n",
    "    9: (0, 0, 0),        # Black\n",
    "    10: (169, 169, 169)  # Dark Grey\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedd37b",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a4ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/val/labels.cache\n"
     ]
    }
   ],
   "source": [
    "def remove_cache_files(directory):\n",
    "    cache_files = glob.glob(os.path.join(directory, \"*.cache\"))\n",
    "    for cache_file in cache_files:\n",
    "        os.remove(cache_file)\n",
    "        print(f\"Removed: {cache_file}\")\n",
    "        \n",
    "with open(\"/home/rshah133/bcd/dataset.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3e262",
   "metadata": {},
   "source": [
    "Model Setup, Change the model and hyperparameters. Keep epochs atleast 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56688054-9fb2-4e23-ac82-76d715e5e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')\n",
    "results = model.train(data = \"/home/rshah133/bcd/dataset.yaml\", epochs = 300, imgsz = 640, batch = 6, device = 0, patience = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae2a47",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/rshah133/bcd/test_dataset.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0309f",
   "metadata": {},
   "source": [
    "## Change path and mention the latest train folder generated\n",
    "\n",
    "* For eg. '/home/rshah133/bcd/runs/detect/train/weights/best.pt'\n",
    "* I have train as the latest file. Next time I run the code it would change to train2. \n",
    "* So please check and change this everytime you run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "599e5b98-4cb5-4aea-8ec7-3d9df13699d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = 'runs/detect/train/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7a724",
   "metadata": {},
   "source": [
    "Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92095830",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "test_img_path = data_loaded['val']\n",
    "results = best_model.predict(source = test_img_path, save = True,  save_txt = True,  conf = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150e326",
   "metadata": {},
   "source": [
    "Run this cell as it is and take screenshot of the output. This code is for calculating the metrics for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_model.val(data = '/home/rshah133/bcd/test_dataset.yaml', conf = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89558bf0",
   "metadata": {},
   "source": [
    "## Change the directory of the variable below\n",
    "\n",
    "* predictions_dir = Directory for the predicted labels. Eg:- \"runs/detect/predict/labels\" \n",
    "* Here predict is variable and can change to predict2, predict3 etc everytime you run it. So change it everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ca6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dir = \"runs/detect/predict/labels\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104f47",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e871-b0d0-4b1a-a837-651b772103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = data_loaded['val']\n",
    "test_labels_dir = os.path.join(os.path.dirname(data_loaded['val']), 'labels')\n",
    "\n",
    "\n",
    "output_labels_dir = \"results/labels\"  # Directory to save ground truth images\n",
    "output_pred_dir = \"results/predictions\"  # Directory to save predicted images\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_pred_dir, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO format labels\n",
    "def read_yolo_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "            confidence = float(parts[5]) if len(parts) > 5 else None\n",
    "            labels.append((int(class_id), x_center, y_center, width, height, confidence))\n",
    "    return labels\n",
    "\n",
    "# Function to draw bounding boxes on images\n",
    "def draw_boxes(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height, confidence = box\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        x_max = int((x_center + width / 2) * w)\n",
    "        y_max = int((y_center + height / 2) * h)\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color_dict[class_id], 2)\n",
    "    return image\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in os.listdir(test_images_dir):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Read ground truth labels\n",
    "        ground_truth_file = os.path.join(test_labels_dir, f\"{base_name}.txt\")\n",
    "        ground_truth_boxes = read_yolo_labels(ground_truth_file) if os.path.exists(ground_truth_file) else []\n",
    "\n",
    "        # Read prediction labels\n",
    "        prediction_file = os.path.join(predictions_dir, f\"{base_name}.txt\")\n",
    "        prediction_boxes = read_yolo_labels(prediction_file) if os.path.exists(prediction_file) else []\n",
    "\n",
    "        # Draw ground truth (green) and predictions (blue)\n",
    "        image_with_boxes_gt = draw_boxes(image.copy(), ground_truth_boxes)\n",
    "        image_with_boxes_pt = draw_boxes(image.copy(), prediction_boxes)\n",
    "\n",
    "        # Save annotated image\n",
    "        gt_output_path = os.path.join(output_labels_dir, image_file)\n",
    "        cv2.imwrite(gt_output_path, image_with_boxes_gt)\n",
    "\n",
    "        pt_output_path = os.path.join(output_pred_dir, image_file)\n",
    "        cv2.imwrite(pt_output_path, image_with_boxes_pt)\n",
    "\n",
    "print(\"Done saving the predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "    label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "    pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Ground Truth')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title('Prediction')\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3605fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.2.1",
   "language": "python",
   "name": "pytorch-gpu-2.2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
