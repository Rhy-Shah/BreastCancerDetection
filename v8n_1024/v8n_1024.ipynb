{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ab9742-190b-465d-9e13-d7a04dc91617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291dd5b9",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_name = { 0: 'Mass',\n",
    "1: 'Spiculation',\n",
    "2: 'Suspicious Calcification',\n",
    "3: 'Architectural Distortion',\n",
    "4: 'Asymmetry',\n",
    "5: 'Focal Asymmetry',\n",
    "6: 'Skin Thickening',\n",
    "7: 'Global Asymmetry',\n",
    "8: 'Suspicious Lymph Node',\n",
    "9: 'Skin Retraction',\n",
    "10: 'Nipple Retraction'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    0: (255, 0, 0),      # Red\n",
    "    1: (0, 255, 0),      # Green\n",
    "    2: (0, 0, 255),      # Blue\n",
    "    3: (255, 255, 0),    # Yellow\n",
    "    4: (255, 165, 0),    # Orange\n",
    "    5: (128, 0, 128),    # Purple\n",
    "    6: (0, 255, 255),    # Cyan\n",
    "    7: (255, 192, 203),  # Pink\n",
    "    8: (128, 128, 0),    # Olive\n",
    "    9: (0, 0, 0),        # Black\n",
    "    10: (169, 169, 169)  # Dark Grey\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedd37b",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a4ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/train/labels.cache\n",
      "Removed: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/val/labels.cache\n"
     ]
    }
   ],
   "source": [
    "def remove_cache_files(directory):\n",
    "    cache_files = glob.glob(os.path.join(directory, \"*.cache\"))\n",
    "    for cache_file in cache_files:\n",
    "        os.remove(cache_file)\n",
    "        print(f\"Removed: {cache_file}\")\n",
    "        \n",
    "with open(\"/home/rshah133/bcd/dataset.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3e262",
   "metadata": {},
   "source": [
    "Model Setup, Change the model and hyperparameters. Keep epochs atleast 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56688054-9fb2-4e23-ac82-76d715e5e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.63 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/home/rshah133/bcd/dataset.yaml, epochs=300, time=None, patience=20, batch=6, imgsz=1024, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737306082.539307  137189 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737306082.542400  137189 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753457  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3,012,993 parameters, 3,012,977 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/train/labels... 112 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 6101.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/rshah133/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/val/labels... 21 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 581.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/rshah133/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000515625), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300      2.19G      3.949      5.864      4.179         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/300      2.13G      3.917      5.663      4.166         51       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/300      2.07G      3.894      5.495       4.12         61       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  6.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/300      2.09G      3.775      5.189      4.078         27       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140   4.75e-05      0.143   8.16e-05    2.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/300      2.11G      3.771      5.219       4.03         51       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140   9.58e-05       0.15   0.000197   5.48e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/300       2.1G      3.654      4.857      3.963         45       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140   0.000133      0.156   0.000276   9.87e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/300      2.07G      3.662      4.785      3.888         48       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140   0.000855      0.173    0.00438    0.00271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/300      2.05G       3.65      4.566      3.843         32       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140      0.145     0.0439    0.00152   0.000482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/300       2.1G      3.584      4.415       3.78         62       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00522     0.0378    0.00556    0.00162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/300      2.06G      3.632      4.624      3.736         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00711     0.0628    0.00921    0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/300      2.08G      3.621      4.497      3.667         48       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00322     0.0366    0.00716    0.00509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/300      2.07G      3.645      4.543      3.667         47       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140   0.000409     0.0303   0.000261   4.28e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/300      2.07G      3.561      4.358      3.583         50       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140      0.143     0.0303   0.000305   4.79e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/300      2.12G      3.608      4.323      3.521         41       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00327     0.0594    0.00758    0.00458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/300      2.08G      3.533      4.319      3.517         56       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00262     0.0833    0.00208   0.000666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/300      2.07G      3.547      4.307      3.456         36       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  6.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00259     0.0205     0.0093    0.00407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/300      2.07G      3.516      4.154       3.41         36       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140      0.165     0.0131    0.00821    0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/300      2.06G      3.583      4.241      3.375         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00208      0.109    0.00206   0.000629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/300      2.06G       3.55      4.151      3.299         20       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00279      0.117    0.00708    0.00231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/300      2.06G      3.487      4.362      3.281         40       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00337     0.0922    0.00692     0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/300      2.07G      3.499      4.143      3.283         41       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00348      0.103    0.00948    0.00208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/300      2.06G      3.518      3.968      3.279         42       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00391     0.0755     0.0133    0.00381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/300      2.05G      3.529       4.14      3.246         12       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00293     0.0912      0.014    0.00322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/300      2.09G       3.53      3.884       3.23         65       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00187     0.0605    0.00317   0.000935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/300       2.1G      3.569      4.074       3.22         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00222     0.0718    0.00217    0.00066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/300      2.07G      3.513      4.023      3.165         38       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00746     0.0294    0.00692    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/300      2.12G      3.483      4.003      3.209         44       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140     0.0109     0.0362    0.00925    0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/300      2.06G      3.531      3.948      3.189         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00933     0.0748    0.00867      0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/300      2.05G      3.469      3.888      3.173         44       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00738     0.0856    0.00732    0.00183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/300      2.06G      3.488      3.674      3.148         63       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140      0.168    0.00848     0.0123    0.00331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/300      2.07G      3.458      3.796      3.126         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140      0.351     0.0068     0.0118    0.00274\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 11, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "31 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.58 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        140    0.00319     0.0366    0.00714    0.00507\n",
      "                  Mass         18         25     0.0199       0.08     0.0468     0.0351\n",
      "           Spiculation         21         85    0.00244      0.176    0.00322   0.000452\n",
      "Suspicious Calcification         14         21          0          0          0          0\n",
      "       Skin Thickening          1          1          0          0          0          0\n",
      "      Global Asymmetry          1          1          0          0          0          0\n",
      " Suspicious Lymph Node          6          6          0          0          0          0\n",
      "       Skin Retraction          1          1          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 1.1ms inference, 0.0ms loss, 48.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.yaml')\n",
    "results = model.train(data = \"/home/rshah133/bcd/dataset.yaml\", epochs = 300, imgsz = 1024, batch = 6, device = 0, patience = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae2a47",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935a3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/train/labels.cache\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/rshah133/bcd/test_dataset.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0309f",
   "metadata": {},
   "source": [
    "## Change path and mention the latest train folder generated\n",
    "\n",
    "* For eg. '/home/rshah133/bcd/runs/detect/train/weights/best.pt'\n",
    "* I have train as the latest file. Next time I run the code it would change to train2. \n",
    "* So please check and change this everytime you run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599e5b98-4cb5-4aea-8ec7-3d9df13699d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = 'runs/detect/train/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7a724",
   "metadata": {},
   "source": [
    "Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92095830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/1560345de7d8277b170ca3842eae6c97_e751e5a947089704457741eea74c2280.jpg: 1024x832 (no detections), 30.6ms\n",
      "image 2/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/21ee099d74242fca1551adb6f2564a15_b73d4e04b69d52ba6f350cc77da54f95.jpg: 1024x832 268 Spiculations, 6.4ms\n",
      "image 3/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/2dfe6025d5954c2925d6288b50dccbea_a20301f2d2cafec6419d759fa7c70c0b.jpg: 1024x736 (no detections), 48.1ms\n",
      "image 4/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/3b9d3e9aa2fcdefd74d4cbfb496694b4_6c571a3fb5a3abe21141333f65b5bf09.jpg: 1024x832 300 Spiculations, 6.6ms\n",
      "image 5/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/43a5db0fd868e525cf75aaf5d53a1863_493609b26e1341ce737a60b5b930a757.jpg: 1024x832 2 Spiculations, 6.1ms\n",
      "image 6/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/50a8bfda39adc93f22a174153632b823_648040dd50a48c66b4819c38536668ef.jpg: 1024x832 (no detections), 6.0ms\n",
      "image 7/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/57674c2def92287668ed5bc51092fbef_dc4694b543793f89c7003f4d52adbbcb.jpg: 1024x832 2 Spiculations, 5.4ms\n",
      "image 8/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/58a2640209d9244ab1eca8f0686effd4_fde1086cce41c66b9efc68270f537837.jpg: 1024x832 19 Spiculations, 5.3ms\n",
      "image 9/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/5d99bedc43c3225261b270fa4bc5181c_33cfef605778cd250f653662ab876afb.jpg: 1024x832 9 Spiculations, 6.0ms\n",
      "image 10/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/60279474726275dcc024f3c67b4d51a3_712150b595e1a4e62c2e344efd56af42.jpg: 1024x832 157 Spiculations, 7.7ms\n",
      "image 11/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/6d4cd11574ad3598cca9b228bcfcc024_8aaea8ad26744fa23f786699ae38d66e.jpg: 1024x832 (no detections), 5.8ms\n",
      "image 12/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/7047eb7f28a47d9f5fee20a6b1e10954_1fa586cd078894845bf4a1648232cde7.jpg: 1024x832 196 Spiculations, 5.5ms\n",
      "image 13/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/7ed7391fe55395a5e33c4254788c1058_52538aa6ccce48fb567875236f7c876c.jpg: 1024x736 (no detections), 11.8ms\n",
      "image 14/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/7fd8b8221c97ba86ff9cc98dcbd98fb8_fc6a348a61d4282a66ac2dc6dbec5981.jpg: 1024x832 (no detections), 6.7ms\n",
      "image 15/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/8caa9e54b30e54edbdcbc771e7386fd7_11dbf2405e94335db8d8011db532a5ac.jpg: 1024x832 3 Spiculations, 6.7ms\n",
      "image 16/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/937f8b7c688c373cff168ea6529a4731_7e2cda8f991e2e14ab585427cbbfd25e.jpg: 1024x736 (no detections), 6.6ms\n",
      "image 17/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/ae4b6f49514c32216a8aabb4b3ad026a_16772df2fc68173354ed7b5684e40a56.jpg: 1024x736 3 Spiculations, 5.9ms\n",
      "image 18/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/b97d038694c1a91de191bae204dd1f2d_0cf9cd3d36a7bfb95e66c0ba482eb8c0.jpg: 1024x832 23 Spiculations, 6.2ms\n",
      "image 19/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/bf90ae111b0e4727bc583fe31114b1d6_c198e90ae80f0038f051957d1cf8a857.jpg: 1024x736 (no detections), 6.0ms\n",
      "image 20/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/cf70a8015962943d8637b8b5db34ff25_da860c7c1030662471437b1c9d32ed81.jpg: 1024x736 (no detections), 5.5ms\n",
      "image 21/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/e11cb06c657324160b15e72be89f6c28_f54b07517cb46e8a59c1c10748bdb5ed.jpg: 1024x736 1 Spiculation, 5.7ms\n",
      "image 22/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/e480e873a319b8caa10cb1508d537252_2a04163be4ae7d6f70732904202cc934.jpg: 1024x832 30 Spiculations, 7.0ms\n",
      "image 23/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/e480e873a319b8caa10cb1508d537252_cc646314fbef56ce4636bb29623e5ad2.jpg: 1024x832 34 Spiculations, 7.8ms\n",
      "image 24/24 /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/images/eba1e3ad235efbefcd1284fd5cab3895_47b7e7e5dc8e865511610b1225ce4f05.jpg: 1024x832 221 Spiculations, 6.1ms\n",
      "Speed: 6.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "15 labels saved to runs/detect/predict/labels\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "test_img_path = data_loaded['val']\n",
    "results = best_model.predict(source = test_img_path, save = True,  save_txt = True,  conf = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150e326",
   "metadata": {},
   "source": [
    "Run this cell as it is and take screenshot of the output. This code is for calculating the metrics for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/labels... 24 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 183024.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/rshah133/breast_cancer_detection/train_val_birads5_test_birads5/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/rshah133/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "metrics = best_model.val(data = '/home/rshah133/bcd/test_dataset.yaml', conf = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89558bf0",
   "metadata": {},
   "source": [
    "## Change the directory of the variable below\n",
    "\n",
    "* predictions_dir = Directory for the predicted labels. Eg:- \"runs/detect/predict/labels\" \n",
    "* Here predict is variable and can change to predict2, predict3 etc everytime you run it. So change it everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1ca6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dir = \"runs/detect/predict/labels\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104f47",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e871-b0d0-4b1a-a837-651b772103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = data_loaded['val']\n",
    "test_labels_dir = os.path.join(os.path.dirname(data_loaded['val']), 'labels')\n",
    "\n",
    "\n",
    "output_labels_dir = \"results/labels\"  # Directory to save ground truth images\n",
    "output_pred_dir = \"results/predictions\"  # Directory to save predicted images\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_pred_dir, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO format labels\n",
    "def read_yolo_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "            confidence = float(parts[5]) if len(parts) > 5 else None\n",
    "            labels.append((int(class_id), x_center, y_center, width, height, confidence))\n",
    "    return labels\n",
    "\n",
    "# Function to draw bounding boxes on images\n",
    "def draw_boxes(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height, confidence = box\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        x_max = int((x_center + width / 2) * w)\n",
    "        y_max = int((y_center + height / 2) * h)\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color_dict[class_id], 2)\n",
    "    return image\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in os.listdir(test_images_dir):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Read ground truth labels\n",
    "        ground_truth_file = os.path.join(test_labels_dir, f\"{base_name}.txt\")\n",
    "        ground_truth_boxes = read_yolo_labels(ground_truth_file) if os.path.exists(ground_truth_file) else []\n",
    "\n",
    "        # Read prediction labels\n",
    "        prediction_file = os.path.join(predictions_dir, f\"{base_name}.txt\")\n",
    "        prediction_boxes = read_yolo_labels(prediction_file) if os.path.exists(prediction_file) else []\n",
    "\n",
    "        # Draw ground truth (green) and predictions (blue)\n",
    "        image_with_boxes_gt = draw_boxes(image.copy(), ground_truth_boxes)\n",
    "        image_with_boxes_pt = draw_boxes(image.copy(), prediction_boxes)\n",
    "\n",
    "        # Save annotated image\n",
    "        gt_output_path = os.path.join(output_labels_dir, image_file)\n",
    "        cv2.imwrite(gt_output_path, image_with_boxes_gt)\n",
    "\n",
    "        pt_output_path = os.path.join(output_pred_dir, image_file)\n",
    "        cv2.imwrite(pt_output_path, image_with_boxes_pt)\n",
    "\n",
    "print(\"Done saving the predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "    label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "    pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Ground Truth')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title('Prediction')\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3605fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
