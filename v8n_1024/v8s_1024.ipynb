{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5947e30b",
   "metadata": {},
   "source": [
    "Please install the necessary libraries using your terminal/shell in your env before running the code. You can check all the libraries mentioned in the next code block. To install any library you can use either one of the code mentioned below\n",
    "\n",
    "pip install library_name\n",
    "\n",
    "pip3 install library_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "import numpy as np\n",
    "from yolo_cam.eigen_cam import EigenCAM\n",
    "from yolo_cam.utils.image import show_cam_on_image\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_name = { 0: 'Mass',\n",
    "1: 'Spiculation',\n",
    "2: 'Suspicious Calcification',\n",
    "3: 'Architectural Distortion',\n",
    "4: 'Asymmetry',\n",
    "5: 'Focal Asymmetry',\n",
    "6: 'Skin Thickening',\n",
    "7: 'Global Asymmetry',\n",
    "8: 'Suspicious Lymph Node',\n",
    "9: 'Skin Retraction',\n",
    "10: 'Nipple Retraction'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    0: (255, 0, 0),      # Red\n",
    "    1: (0, 255, 0),      # Green\n",
    "    2: (0, 0, 255),      # Blue\n",
    "    3: (255, 255, 0),    # Yellow\n",
    "    4: (255, 165, 0),    # Orange\n",
    "    5: (128, 0, 128),    # Purple\n",
    "    6: (0, 255, 255),    # Cyan\n",
    "    7: (255, 192, 203),  # Pink\n",
    "    8: (128, 128, 0),    # Olive\n",
    "    9: (0, 0, 0),        # Black\n",
    "    10: (169, 169, 169)  # Dark Grey\n",
    "}\n",
    "\n",
    "output_labels_dir = \"results/labels\"  # Directory to save ground truth images\n",
    "output_pred_dir = \"results/predictions\"  # Directory to save predicted images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedd37b",
   "metadata": {},
   "source": [
    "Mention dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset.yaml\"\n",
    "\n",
    "def remove_cache_files(directory):\n",
    "    cache_files = glob.glob(os.path.join(directory, \"*.cache\"))\n",
    "    for cache_file in cache_files:\n",
    "        os.remove(cache_file)\n",
    "        print(f\"Removed: {cache_file}\")\n",
    "        \n",
    "with open(path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c41e18",
   "metadata": {},
   "source": [
    "Change the model and hyperparameters.\n",
    "\n",
    "* Epochs = keep minimum 200\n",
    "* imgsz = change acc to your model assigned\n",
    "* patience = number of epochs model will check for accuracy improvement and then stop if accuracy is not improving\n",
    "* set device = [0,1] if you have 2 GPUs requested and device = 0 if only 1 GPU/CPU\n",
    "* save = True, this will help you save the model checkpoints on its own \n",
    "* save_period = 10, this is the number of epochs after which model will save the checkpoints\n",
    "* resume = True, if kernel crashes, model will continue training from the previous checkpoint\n",
    "* iou = keep iou between 0.5-0.7 and check for best metrics (hyperparameter to play with)\n",
    "* optimzer  = AdamW is the best for our model from what I have noticed. you can experiment if you want\n",
    "* learning rate, momentum, and weight decay are few more hyperparamerts you can play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s.yaml')\n",
    "results = model.train(data = path, epochs = 200, imgsz = 1024, batch = 10, name = 'checkpoint', device = [0,1], patience = 25, save = True, save_period = 10, exist_ok = True, resume = True, iou = 0.5, optimizer = 'AdamW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d439060",
   "metadata": {},
   "source": [
    "Implemented Tensorboard. Code will redirect you to a link which should be opened in **Google Chrome** if nothing is getting displayed on safari.  You can choose not to run this code block if you want to not see the dashboard and save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe087fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill 1869322\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/detect/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae2a47",
   "metadata": {},
   "source": [
    "Mention test_dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"test_dataset.yaml\"\n",
    "\n",
    "with open(test_path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7a724",
   "metadata": {},
   "source": [
    "Predicting on test data. Please set the prediction_progress.json to 0 by opening everytime when you want to predict on the test data from the start or it will resume from where it stopped last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907270",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_file = 'prediction_progress.json'\n",
    "\n",
    "def save_progress(current_index):\n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump({'last_processed': current_index}, f)\n",
    "\n",
    "def load_progress():\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            return json.load(f)['last_processed']\n",
    "    return 0\n",
    "\n",
    "# Loading the best model\n",
    "best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "\n",
    "test_img_path = data_loaded['val']\n",
    "\n",
    "start_index = load_progress()\n",
    "\n",
    "chunk_size = 48  # Adjust based on your available memory\n",
    "for i in range(start_index, len(test_img_path), chunk_size):\n",
    "    chunk_end = min(i + chunk_size, len(test_img_path))\n",
    "    current_chunk = test_img_path[i:chunk_end]\n",
    "    \n",
    "    try:\n",
    "        results = best_model.predict(source = current_chunk, save = True, save_txt = True, conf = 0.10, batch = chunk_size//4, stream = True)\n",
    "        \n",
    "        # code for post - processing results for later\n",
    "        for r in results:\n",
    "            pass  \n",
    "            \n",
    "        save_progress(chunk_end)\n",
    "        \n",
    "    except Exception as e:\n",
    "        save_progress(i)\n",
    "        print(f\"Prediction stopped at image {i}. Progress saved.\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92095830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "# test_img_path = data_loaded['val']\n",
    "# results = best_model.predict(source = test_img_path, save = True,  save_txt = True,  conf = 0.10, batch = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150e326",
   "metadata": {},
   "source": [
    "Run this cell as it is and take screenshot of the output. This code is for calculating the metrics for test data\n",
    "\n",
    "u can play with conf keep between 0.05-0.2 (for our use case). lower value means it predicts more but with less accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_model.val(data = test_path, conf = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1198cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_dirs():\n",
    "    base_dir = \"runs/detect\"\n",
    "    \n",
    "    predict_dirs = [d for d in os.listdir(base_dir) if d.startswith('predict')]\n",
    "    predict_dirs.sort(key=lambda x: int(x.replace('predict', '')) if x != 'predict' else 0)\n",
    "    \n",
    "    return f\"{base_dir}/{predict_dirs[-1]}/labels\"\n",
    "\n",
    "predictions_dir = get_prediction_dirs()\n",
    "predictions_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e871-b0d0-4b1a-a837-651b772103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = data_loaded['val']\n",
    "test_labels_dir = os.path.join(os.path.dirname(data_loaded['val']), 'labels')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_pred_dir, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO format labels\n",
    "def read_yolo_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "            confidence = float(parts[5]) if len(parts) > 5 else None\n",
    "            labels.append((int(class_id), x_center, y_center, width, height, confidence))\n",
    "    return labels\n",
    "\n",
    "# Function to draw bounding boxes on images\n",
    "def draw_boxes(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height, confidence = box\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        x_max = int((x_center + width / 2) * w)\n",
    "        y_max = int((y_center + height / 2) * h)\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color_dict[class_id], 2)\n",
    "    return image\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in os.listdir(test_images_dir):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Read ground truth labels\n",
    "        ground_truth_file = os.path.join(test_labels_dir, f\"{base_name}.txt\")\n",
    "        ground_truth_boxes = read_yolo_labels(ground_truth_file) if os.path.exists(ground_truth_file) else []\n",
    "\n",
    "        # Read prediction labels\n",
    "        prediction_file = os.path.join(predictions_dir, f\"{base_name}.txt\")\n",
    "        prediction_boxes = read_yolo_labels(prediction_file) if os.path.exists(prediction_file) else []\n",
    "\n",
    "        # Draw ground truth (green) and predictions (blue)\n",
    "        image_with_boxes_gt = draw_boxes(image.copy(), ground_truth_boxes)\n",
    "        image_with_boxes_pt = draw_boxes(image.copy(), prediction_boxes)\n",
    "\n",
    "        # Save annotated image\n",
    "        gt_output_path = os.path.join(output_labels_dir, image_file)\n",
    "        cv2.imwrite(gt_output_path, image_with_boxes_gt)\n",
    "\n",
    "        pt_output_path = os.path.join(output_pred_dir, image_file)\n",
    "        cv2.imwrite(pt_output_path, image_with_boxes_pt)\n",
    "\n",
    "print(\"Done saving the predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504c186",
   "metadata": {},
   "source": [
    "Code to combine images in a single pdf. This code take upto 20mins to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "c = 0\n",
    "pdf_file_path = \"combined_images.pdf\"\n",
    "\n",
    "# model = YOLO('/home/rshah133/bcd/v8n_1024/runs/detect/checkpoint/weights/best.pt')\n",
    "model = model.cpu()\n",
    "target_layers = [model.model.model[-4]]\n",
    "cam = EigenCAM(model, target_layers, task='od')\n",
    "\n",
    "\n",
    "with PdfPages(pdf_file_path) as pdf:\n",
    "    for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "        label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "        pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "        \n",
    "        img = cv2.resize(pred_img, (640, 640))\n",
    "        rgb_img = img.copy()\n",
    "        img = np.float32(img) / 255\n",
    "        \n",
    "        grayscale_cam = cam(rgb_img)[0, :, :]\n",
    "        \n",
    "        grayscale_cam_resized = cv2.resize(grayscale_cam, (img.shape[1], img.shape[0]))\n",
    "        cam_image = show_cam_on_image(img, grayscale_cam_resized, use_rgb=True)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(16, 6))\n",
    "        axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[0].set_title('Ground Truth')\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[1].set_title('Prediction')\n",
    "        axs[1].axis('off')\n",
    "        axs[2].imshow(cv2.cvtColor(cam_image, cv2.COLOR_BGR2RGB))\n",
    "        axs[2].set_title('EigenCAM Explainable AI')\n",
    "        axs[2].axis('off')\n",
    "        \n",
    "        c+=1\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "    \n",
    "print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "\n",
    "# output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "# output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "# pdf_file_path = \"combined_images.pdf\"\n",
    "# with PdfPages(pdf_file_path) as pdf:\n",
    "#     for label_file, pred_file in zip(output_labels_file_names[:5], output_pred_file_names[:5]):\n",
    "#         label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "#         pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#         fig.suptitle(f\"Image: {label_file}\", fontsize=12)\n",
    "#         axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[0].set_title('Ground Truth')\n",
    "#         axs[0].axis('off')\n",
    "#         axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[1].set_title('Prediction')\n",
    "#         axs[1].axis('off')\n",
    "#         plt.tight_layout()\n",
    "#         c += 1\n",
    "        \n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)\n",
    "\n",
    "# print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
