{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5947e30b",
   "metadata": {},
   "source": [
    "Please install the necessary libraries using your terminal/shell in your env before running the code. You can check all the libraries mentioned in the next code block. To install any library you can use either one of the code mentioned below\n",
    "\n",
    "pip install library_name\n",
    "\n",
    "pip3 install library_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "import numpy as np\n",
    "from yolo_cam.eigen_cam import EigenCAM\n",
    "from yolo_cam.utils.image import show_cam_on_image\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_name = { 0: 'Mass',\n",
    "1: 'Spiculation',\n",
    "2: 'Suspicious Calcification',\n",
    "3: 'Architectural Distortion',\n",
    "4: 'Asymmetry',\n",
    "5: 'Focal Asymmetry',\n",
    "6: 'Skin Thickening',\n",
    "7: 'Global Asymmetry',\n",
    "8: 'Suspicious Lymph Node',\n",
    "9: 'Skin Retraction',\n",
    "10: 'Nipple Retraction'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    0: (255, 0, 0),      # Red\n",
    "    1: (0, 255, 0),      # Green\n",
    "    2: (0, 0, 255),      # Blue\n",
    "    3: (255, 255, 0),    # Yellow\n",
    "    4: (255, 165, 0),    # Orange\n",
    "    5: (128, 0, 128),    # Purple\n",
    "    6: (0, 255, 255),    # Cyan\n",
    "    7: (255, 192, 203),  # Pink\n",
    "    8: (128, 128, 0),    # Olive\n",
    "    9: (0, 0, 0),        # Black\n",
    "    10: (169, 169, 169)  # Dark Grey\n",
    "}\n",
    "\n",
    "output_labels_dir = \"results/labels\"  # Directory to save ground truth images\n",
    "output_pred_dir = \"results/predictions\"  # Directory to save predicted images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedd37b",
   "metadata": {},
   "source": [
    "Mention dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a4ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset.yaml\"\n",
    "\n",
    "def remove_cache_files(directory):\n",
    "    cache_files = glob.glob(os.path.join(directory, \"*.cache\"))\n",
    "    for cache_file in cache_files:\n",
    "        os.remove(cache_file)\n",
    "        print(f\"Removed: {cache_file}\")\n",
    "        \n",
    "with open(path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c41e18",
   "metadata": {},
   "source": [
    "Change the model and hyperparameters.\n",
    "\n",
    "* Epochs = keep minimum 200\n",
    "* imgsz = change acc to your model assigned\n",
    "* patience = number of epochs model will check for accuracy improvement and then stop if accuracy is not improving\n",
    "* set device = [0,1] if you have 2 GPUs requested and device = 0 if only 1 GPU/CPU\n",
    "* save = True, this will help you save the model checkpoints on its own \n",
    "* save_period = 10, this is the number of epochs after which model will save the checkpoints\n",
    "* resume = True, if kernel crashes, model will continue training from the previous checkpoint\n",
    "* iou = keep iou between 0.5-0.7 and check for best metrics (hyperparameter to play with)\n",
    "* optimzer  = AdamW is the best for our model from what I have noticed. you can experiment if you want\n",
    "* learning rate, momentum, and weight decay are few more hyperparamerts you can play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf44d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.69 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.68 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=dataset.yaml, epochs=200, time=None, patience=25, batch=10, imgsz=1024, save=True, save_period=10, cache=False, device=[0, 1], workers=8, project=None, name=checkpoint, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=None, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738133873.172429  893145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738133873.175626  893145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2120305  ultralytics.nn.modules.head.Detect           [11, [128, 256, 512]]         \n",
      "YOLOv8s summary: 225 layers, 11,139,857 parameters, 11,139,841 gradients, 28.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /packages/apps/jupyter/2023-10-09/bin/python -m torch.distributed.run --nproc_per_node 2 --master_port 48785 /home/rshah133/.config/Ultralytics/DDP/_temp_b9f_sfdr23456177214224.py\n",
      "Ultralytics 8.3.68 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81156MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738133949.885821  894472 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738133949.889995  894472 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/checkpoint', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=11\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/rshah133/bcd/dataset/train/labels... 337 images, 42 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:00<00:00, 916.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/rshah133/bcd/dataset/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/rshah133/bcd/dataset/val/labels... 38 images, 8 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 987.85it/s]\n",
      "/home/rshah133/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/rshah133/bcd/dataset/val/labels.cache\n",
      "Plotting labels to runs/detect/checkpoint/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/checkpoint\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200      3.62G      3.852      5.272      3.587         20       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  5.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.091     0.0108   9.91e-05   2.12e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/200      3.42G      3.698      4.369       3.04         59       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000408     0.0147     0.0002    5.8e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/200      3.49G      3.709       4.37      2.931         57       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.273   0.000834   0.000121   2.37e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/200      3.42G      3.589       4.38      2.914         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000221     0.0217   0.000157   2.75e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/200      3.31G      4.016      4.483      3.192         44       1024:   3%|â–Ž         | 1/34 [00:00<00:04,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/200      3.32G      3.691      4.261      2.971         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000409     0.0317   0.000309   4.92e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/200      3.43G      3.663      4.215      2.926         27       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000306     0.0317   0.000241   4.56e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/200      3.36G      3.646      4.242      2.929         18       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000364     0.0134   0.000228      8e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/200      3.34G      3.745      4.152       3.02         33       1024:   6%|â–Œ         | 2/34 [00:00<00:02, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/200      3.35G      3.626      4.135      2.914         29       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000204     0.0209    0.00013   2.26e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/200      3.44G      3.651      4.185      2.879         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000357     0.0367   0.000825   0.000172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/200      3.33G      3.692      4.385      2.908         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000859      0.036   0.000761   0.000212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/200      3.45G      3.616      4.083      2.878         14       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000136     0.0142   7.93e-05   1.48e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/200      3.45G      3.644          4      2.924          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.002     0.0624    0.00269    0.00106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/200      3.36G      3.567      4.084      2.894          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00379     0.0635    0.00962    0.00302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/200      3.38G      3.677      4.055      2.942         46       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000437     0.0317    0.00032   6.91e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/200      3.37G      3.595      4.103       2.85         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000539     0.0392   0.000517   8.03e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/200      3.42G       3.64      4.078      2.876         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00168     0.0684    0.00334   0.000802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/200       3.5G      3.677      4.256      2.911         30       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00301     0.0566    0.00404    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/200       3.3G       3.59      3.904      2.876         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00121     0.0774    0.00173   0.000415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/200       3.3G      3.635      3.983      2.869         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000565     0.0368   0.000623   0.000122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/200      3.32G      3.638      4.049      2.887          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000509      0.036   0.000837   0.000165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/200      3.45G      3.634       4.06      2.898         15       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00158     0.0266    0.00275    0.00108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/200      3.45G       3.58      3.924      2.877         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00127     0.0191   0.000685   9.95e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/200      3.32G      3.646      3.876      2.898         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00108      0.066   0.000896    0.00024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/200      3.43G      3.626      3.875      2.907         11       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 11.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00042    0.00587   0.000238   7.87e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/200      3.37G      3.637      3.833      2.894         41       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00214     0.0241    0.00157   0.000439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/200      3.31G      3.615      3.737      2.882         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000861      0.047   0.000975   0.000243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/200      3.31G      3.554      3.795      2.834         63       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00202      0.132    0.00516    0.00156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/200       3.3G      3.657       3.79      2.882         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00155      0.105    0.00282   0.000929\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/200      3.36G      3.573      3.664      2.889         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00159     0.0562    0.00387   0.000729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/200      3.34G      3.744      4.174      2.907          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00221      0.114    0.00565    0.00153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/200      3.44G      3.607      3.642      2.879         15       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.221    0.00981    0.00881    0.00278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/200      3.32G      3.532      3.586       2.89         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.306     0.0042    0.00577    0.00138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/200       3.3G      3.538      3.613      2.801         60       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.281     0.0158     0.0121    0.00412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/200      3.33G      3.591      3.653       2.83         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.187     0.0233    0.00658    0.00202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/200      3.45G      3.543      3.484      2.816         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.31     0.0193     0.0151    0.00371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/200      3.34G      3.509      3.685      2.814         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 11.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.184    0.00568   0.000681   0.000152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/200       3.3G      3.459      3.403      2.788         37       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.312     0.0206     0.0145    0.00317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/200      3.36G      3.338      3.218      2.832         43       1024:   3%|â–Ž         | 1/34 [00:00<00:03,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/200      3.36G      3.504      3.538      2.828         20       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165   0.000806     0.0447   0.000739   0.000162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/200      3.31G       3.37      3.496       2.73         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.28    0.00754    0.00331   0.000751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/200      3.44G      3.342      3.417      2.804         16       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00279     0.0417    0.00285   0.000911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/200      3.38G      3.353      3.606      2.742         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00146    0.00837   0.000785   0.000132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/200       3.3G      3.368      3.511       2.79         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00209     0.0199    0.00328    0.00108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/200       3.3G      3.265      3.466      2.727         13       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.75     0.0101     0.0126     0.0042\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/200      3.45G      3.201      3.512       2.69         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 11.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00516      0.234     0.0126    0.00373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/200       3.3G      3.127       3.26      2.678         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.532     0.0175     0.0176    0.00755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/200       3.3G      3.198      3.344      2.714         18       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.183    0.00818   0.000262   5.66e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/200      3.32G      3.138      3.417      2.661         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.304    0.00337     0.0137     0.0036\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/200      3.34G      3.029      3.401      2.605         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.491     0.0126     0.0194    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/200      3.34G      3.075      3.416      2.623          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00113     0.0951    0.00114   0.000275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/200      3.47G       3.04      3.121      2.617         17       1024:   3%|â–Ž         | 1/34 [00:00<00:03,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/200      3.48G      3.022       3.34      2.633         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.554     0.0142     0.0216    0.00642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/200      3.47G      3.013      3.406      2.556         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 24.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0105     0.0167     0.0102     0.0035\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/200      3.44G      3.008      3.372      2.543         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.393     0.0345     0.0199    0.00412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/200      3.46G      2.968      3.266      2.519         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.356     0.0042    0.00576    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/200      3.31G      2.946      3.354      2.474         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.492     0.0385     0.0638     0.0154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/200      3.42G       2.92      3.361      2.496         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.217     0.0189    0.00692    0.00112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/200      3.31G      2.907      3.334      2.481         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.182    0.00905    0.00114   0.000459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/200      3.31G       2.82      3.366       2.36         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.41      0.026     0.0246    0.00773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/200       3.3G      2.781      3.197      2.377         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.495    0.00337     0.0115    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/200      3.36G      2.839      3.174      2.339         26       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 25.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0108     0.0151     0.0071    0.00151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/200       3.3G      2.816      3.284      2.349         30       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.298     0.0361     0.0153    0.00363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/200      3.46G      2.772      3.273      2.343         14       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0358      0.215     0.0449      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/200      3.32G      2.729      3.172        2.3         37       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.574     0.0101    0.00539    0.00106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/200      3.49G      2.712       2.99      2.328         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.606     0.0318     0.0308    0.00939\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/200      3.36G      2.773      3.162       2.34         19       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.683      0.025      0.019    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/200      3.37G      2.724      3.034      2.325         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.612     0.0208     0.0135    0.00366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/200       3.3G      2.763      3.338      2.378         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.581     0.0411     0.0351     0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/200      3.34G      2.855      2.786      2.451         49       1024:   3%|â–Ž         | 1/34 [00:00<00:05,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/200      3.34G      2.783      3.028      2.341         30       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.47     0.0101    0.00745    0.00313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/200      3.34G      2.801      3.179      2.373         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.493     0.0291     0.0266    0.00828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/200       3.3G      2.669      3.092      2.328         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.596     0.0676     0.0687     0.0315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/200      3.29G      2.746      3.106      2.381         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.329    0.00697     0.0148     0.0047\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/200      3.31G      2.803      3.178      2.392         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.493     0.0313     0.0147    0.00425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/200      3.34G      2.772      3.181      2.409         46       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.708     0.0345     0.0395     0.0147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/200      3.45G      2.683      3.087      2.307         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.677     0.0783     0.0538      0.019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/200      3.31G      2.745      3.087      2.332         22       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.589     0.0185      0.054     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/200      3.34G      2.652      3.052      2.246         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.651     0.0231     0.0239     0.0107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/200      3.46G      2.675      3.003      2.331         38       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00748     0.0919     0.0136    0.00512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/200      3.33G      2.708      3.253       2.33          7       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00157      0.098    0.00634    0.00274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/200      3.33G       2.61      2.995      2.254         35       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.589     0.0342     0.0221    0.00536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/200      3.36G      2.651      2.976      2.277         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.574     0.0149    0.00767    0.00149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/200      3.34G      2.606      2.993      2.275         26       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.701     0.0327     0.0137    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/200      3.31G      2.678      3.007      2.379         19       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.722     0.0351     0.0396     0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/200      3.49G      2.871      3.865      2.612         37       1024:   3%|â–Ž         | 1/34 [00:00<00:04,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/200      3.49G      2.704      3.041       2.32         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00124     0.0516     0.0008   0.000261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/200      3.49G      2.683      3.064      2.202         14       1024:   3%|â–Ž         | 1/34 [00:00<00:03,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/200       3.5G      2.693      3.019      2.312         26       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00109     0.0445   0.000709   0.000182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/200      3.32G      2.652       3.06      2.311         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.571     0.0116    0.00898    0.00117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/200      3.29G      2.757      3.254      2.335          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.724     0.0124     0.0187    0.00865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/200      3.31G      2.658      2.919      2.273         26       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.548     0.0151    0.00288   0.000896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/200      3.33G      2.634      3.206      2.255         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 11.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.763      0.036     0.0768     0.0266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/200      3.45G      2.505      2.859      2.177         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.782    0.00966     0.0197    0.00764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/200      3.46G      2.549       2.82      2.199         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0229      0.134     0.0338      0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/200       3.3G      2.692       2.98      2.322         29       1024:   3%|â–Ž         | 1/34 [00:00<00:03,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/200      3.31G      2.636      3.167      2.291         61       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0056      0.158     0.0148    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/200      3.33G      2.558      2.939      2.204         26       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.557     0.0139    0.00841    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/200      3.38G      2.518      2.763      2.228         25       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165        0.7     0.0437     0.0308    0.00847\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/200      3.46G      2.595      2.994      2.343         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.694     0.0598     0.0755     0.0321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/200       3.3G      2.515      2.818      2.269         35       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165    0.00113      0.148    0.00506    0.00106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/200      3.32G      2.622      2.959      2.277         29       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.684     0.0336      0.075     0.0262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/200      3.36G      2.572      2.926      2.211         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0115      0.123     0.0261    0.00947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/200      3.29G       2.52      2.807       2.16         18       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.697     0.0067    0.00942    0.00329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/200      3.34G      2.541      2.853      2.202         15       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.743     0.0126    0.00936    0.00247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/200      3.43G       2.52      2.858      2.171         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.733     0.0344     0.0701     0.0365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/200      3.31G      2.538      2.741      2.192         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.591     0.0392     0.0275     0.0063\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    101/200      3.33G      2.506      2.863       2.15         21       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.594      0.052     0.0831     0.0337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    102/200      3.32G       2.51      2.856      2.174          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.705      0.031     0.0594     0.0265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    103/200      3.29G      2.507      2.837       2.14         27       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.716     0.0584      0.057     0.0169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    104/200      3.35G      2.532      2.711      2.202         20       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165     0.0138      0.206     0.0333    0.00782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/200      3.31G      2.508      2.555      2.176         75       1024:   3%|â–Ž         | 1/34 [00:00<00:03,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/200      3.32G      2.488      2.779      2.161         19       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165       0.66     0.0302     0.0174     0.0062\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    106/200      3.36G      2.555       2.89      2.151         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.585     0.0224     0.0274    0.00964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    107/200      3.32G      2.512      2.911      2.144         13       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 11.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.521     0.0384      0.044     0.0203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    108/200      3.43G      2.452      2.725      2.138          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.775     0.0227      0.027    0.00853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    109/200       3.3G      2.421      2.687      2.108         18       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.677     0.0277     0.0626     0.0331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    110/200      3.32G      2.507      2.887      2.233         19       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.562     0.0101    0.00847    0.00151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    111/200      3.35G      2.431      2.769      2.183         29       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.675     0.0126     0.0202    0.00579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    112/200       3.3G      2.511      2.856      2.205         27       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.719    0.00504     0.0145    0.00518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    113/200      3.31G      2.507      2.822      2.201         13       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.385     0.0804      0.034     0.0114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    114/200       3.3G      2.529      2.768      2.166         15       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.689     0.0502     0.0268    0.00994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    115/200      3.46G      2.478      2.798      2.113         24       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00,  9.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.659     0.0118     0.0123    0.00415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    116/200      3.32G      2.479       2.75      2.142         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.837    0.00587     0.0165    0.00608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    117/200      3.29G      2.432      2.743      2.113         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.697     0.0319     0.0508     0.0219\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    118/200      3.31G      2.412      2.696      2.129         28       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.696     0.0413     0.0456     0.0149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    119/200      3.44G      2.479      2.784      2.133         33       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.686     0.0515     0.0189    0.00567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    120/200      3.32G      2.363      2.585       2.05         31       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 20.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.707     0.0485     0.0447      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    121/200      3.47G      2.403      2.632      2.109         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.685       0.05     0.0492     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    122/200      3.33G       2.44       2.71      2.174         34       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.744     0.0126     0.0079    0.00194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    123/200      3.43G       2.37      2.533      2.093         23       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.754     0.0118      0.014     0.0024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    124/200      3.42G      2.297       2.45      2.047         52       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.757     0.0277     0.0228    0.00791\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 99, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "124 epochs completed in 0.154 hours.\n",
      "Optimizer stripped from runs/detect/checkpoint/weights/last.pt, 22.6MB\n",
      "Optimizer stripped from runs/detect/checkpoint/weights/best.pt, 22.6MB\n",
      "\n",
      "Validating runs/detect/checkpoint/weights/best.pt...\n",
      "Ultralytics 8.3.68 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81156MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11,129,841 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         38        165      0.731     0.0334     0.0701     0.0363\n",
      "                  Mass         18         27      0.262      0.198      0.181     0.0741\n",
      "           Spiculation         30        109      0.309       0.11      0.142     0.0477\n",
      "Suspicious Calcification         12         16      0.473     0.0592     0.0707     0.0234\n",
      "Architectural Distortion          1          1          1          0          0          0\n",
      "             Asymmetry          3          3          1          0      0.356      0.249\n",
      "       Focal Asymmetry          2          2          1          0     0.0209    0.00492\n",
      "       Skin Thickening          1          1          1          0          0          0\n",
      "      Global Asymmetry          1          1          1          0          0          0\n",
      " Suspicious Lymph Node          2          2          1          0          0          0\n",
      "       Skin Retraction          2          2          1          0          0          0\n",
      "     Nipple Retraction          1          1          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/checkpoint\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8s.yaml')\n",
    "results = model.train(data = path, epochs = 200, imgsz = 1024, batch = 10, name = 'checkpoint', device = [0,1], patience = 25, save = True, save_period = 10, exist_ok = True, resume = True, iou = 0.5, optimizer = 'AdamW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d439060",
   "metadata": {},
   "source": [
    "Implemented Tensorboard. Code will redirect you to a link which should be opened in **Google Chrome** if nothing is getting displayed on safari.  You can choose not to run this code block if you want to not see the dashboard and save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe087fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/home/rshah133/.local/bin/tensorboard\", line 5, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"/home/rshah133/.local/lib/python3.11/site-packages/tensorboard/main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"/home/rshah133/.local/lib/python3.11/site-packages/tensorboard/default.py\", line 30, in <module>\n",
       "    import pkg_resources\n",
       "  File \"/home/rshah133/.local/lib/python3.11/site-packages/pkg_resources/__init__.py\", line 90, in <module>\n",
       "    from jaraco.text import drop_comment, join_continuation, yield_lines\n",
       "  File \"/home/rshah133/.local/lib/python3.11/site-packages/setuptools/_vendor/jaraco/text/__init__.py\", line 12, in <module>\n",
       "    from jaraco.context import ExceptionTrap\n",
       "  File \"/home/rshah133/.local/lib/python3.11/site-packages/setuptools/_vendor/jaraco/context.py\", line 17, in <module>\n",
       "    from backports import tarfile\n",
       "ImportError: cannot import name 'tarfile' from 'backports' (/packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages/backports/__init__.py)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!kill 1869322\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/detect/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae2a47",
   "metadata": {},
   "source": [
    "Mention test_dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935a3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /home/rshah133/bcd/dataset/train/labels.cache\n"
     ]
    }
   ],
   "source": [
    "test_path = \"test_dataset.yaml\"\n",
    "\n",
    "with open(test_path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7a724",
   "metadata": {},
   "source": [
    "Predicting on test data. Please set the prediction_progress.json to 0 by opening everytime when you want to predict on the test data from the start or it will resume from where it stopped last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc907270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/706 /home/rshah133/bcd/dataset/test/images/002460132586dc0c7b88a59dce6e77bd.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 2/706 /home/rshah133/bcd/dataset/test/images/008bc6050f6d31fc255e5d87bcc87ba2.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 3/706 /home/rshah133/bcd/dataset/test/images/008c66563c73b2f5b8e42915b2cd6af5.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 4/706 /home/rshah133/bcd/dataset/test/images/00a6b0d56eb5136c1be2c3d624b04dad.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 5/706 /home/rshah133/bcd/dataset/test/images/01df962b078e38500bf9dd9969a50083.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 6/706 /home/rshah133/bcd/dataset/test/images/03b3656c726cbe0d79c86a25d4296559.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 7/706 /home/rshah133/bcd/dataset/test/images/040cc172596bded4092c44094dc33fb7.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 8/706 /home/rshah133/bcd/dataset/test/images/042733688eecb852ea06140448a8b1bf.jpg: 1024x1024 2 Masss, 6 Spiculations, 2.8ms\n",
      "image 9/706 /home/rshah133/bcd/dataset/test/images/04ddd99e0fad1aeca36740eaacdf5607.jpg: 1024x1024 1 Mass, 1 Spiculation, 2.8ms\n",
      "image 10/706 /home/rshah133/bcd/dataset/test/images/051525b959eefb14e973acc7ab8fcfe0.jpg: 1024x1024 2 Spiculations, 2.8ms\n",
      "image 11/706 /home/rshah133/bcd/dataset/test/images/070170f7ee43d9304852fafdde498b05.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 12/706 /home/rshah133/bcd/dataset/test/images/074775a9e94c93ed3ee32a82d2864c68.jpg: 1024x1024 (no detections), 2.8ms\n",
      "image 13/706 /home/rshah133/bcd/dataset/test/images/07f468d6fff5b3e3b512e4b95cf0cdda.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 14/706 /home/rshah133/bcd/dataset/test/images/07f5863348560d0507bba86c8bba0586.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 15/706 /home/rshah133/bcd/dataset/test/images/080220733f46127184e6e0158d66c2e3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 16/706 /home/rshah133/bcd/dataset/test/images/09025dbf5abd08828ecd4ebf03724341.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 17/706 /home/rshah133/bcd/dataset/test/images/09c7c41323c29e418790f733ffb291c1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 18/706 /home/rshah133/bcd/dataset/test/images/0a783b57dbe25acd10a1a2cfdba1e7a9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 19/706 /home/rshah133/bcd/dataset/test/images/0aa8394efecbfb0f5c4a66ffbd215912.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 20/706 /home/rshah133/bcd/dataset/test/images/0adc8a85d70d053c80a88bb97d108e44.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 21/706 /home/rshah133/bcd/dataset/test/images/0bac94530476031873566b909b8f1161.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 22/706 /home/rshah133/bcd/dataset/test/images/0bcbcbbe010d72178ba66ded4ad519c4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 23/706 /home/rshah133/bcd/dataset/test/images/0c19be554e27e2fdc2fe05ad954e825c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 24/706 /home/rshah133/bcd/dataset/test/images/0c48ef2d25c7fe685e4a9d20b676c3a7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 25/706 /home/rshah133/bcd/dataset/test/images/0c57e79ec6fc2ad0aa38ae8e2f54af07.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 26/706 /home/rshah133/bcd/dataset/test/images/0cc9394905ef9d2527799723b4e87c72.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 27/706 /home/rshah133/bcd/dataset/test/images/0d0826dc6e633a7729ea56fa7390c508.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 28/706 /home/rshah133/bcd/dataset/test/images/0d08356a2638c214fbc6cbeb24251c0c.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 29/706 /home/rshah133/bcd/dataset/test/images/0d58856b402c571d3fa0fc19d26267ca.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 30/706 /home/rshah133/bcd/dataset/test/images/0d6987fc066d2fad238b5c15f4e9bf8e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 31/706 /home/rshah133/bcd/dataset/test/images/0d818b48634b775f4c15cc0dd8a56b69.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 32/706 /home/rshah133/bcd/dataset/test/images/0d9de2c106f154c469b0d0b05980fb5e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 33/706 /home/rshah133/bcd/dataset/test/images/0dac8664468ff3ab7a3e24fda8053cf6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 34/706 /home/rshah133/bcd/dataset/test/images/0e31855d02eadf8670ffaeeaeddbf229.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 35/706 /home/rshah133/bcd/dataset/test/images/0e3db7bbea14c6dd5dbab7b95bfe82e4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 36/706 /home/rshah133/bcd/dataset/test/images/0e9481c18a33d55b1fa0a353f53e0d6a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 37/706 /home/rshah133/bcd/dataset/test/images/0f0009a94c664c2b67ae78fd675f323c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 38/706 /home/rshah133/bcd/dataset/test/images/0f22280d1836afa323f2023d12be9573.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 39/706 /home/rshah133/bcd/dataset/test/images/0f37159abdcef6a062e404df47e8f1ac.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 40/706 /home/rshah133/bcd/dataset/test/images/101906844b5a3d7fab9df630876d24fd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 41/706 /home/rshah133/bcd/dataset/test/images/10e0f362333df810ac84a9db8fb3fd42.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 42/706 /home/rshah133/bcd/dataset/test/images/11ad49282c890423f5bd94803842d89c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 43/706 /home/rshah133/bcd/dataset/test/images/132095e759b34fba0adcba4205e1b513.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 44/706 /home/rshah133/bcd/dataset/test/images/136a7d195b654c4bf862fdd076c77574.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 45/706 /home/rshah133/bcd/dataset/test/images/13dcce4e628d544820e41c43275b7806.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 46/706 /home/rshah133/bcd/dataset/test/images/153e6a233a6694e96db4356a947c9678.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 47/706 /home/rshah133/bcd/dataset/test/images/1545d3528b9cc99bcdf09d4b2b434f59.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 48/706 /home/rshah133/bcd/dataset/test/images/15c8e59fdfafb3deefc80c5a9e8a42d0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 49/706 /home/rshah133/bcd/dataset/test/images/15fc491b06ef82774b6b8fc6ab09ef23.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 50/706 /home/rshah133/bcd/dataset/test/images/164ebeb7229eed711a9e91b572a902ff.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 51/706 /home/rshah133/bcd/dataset/test/images/16a7ae04fb0ec0039afbceb6c920906f.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 52/706 /home/rshah133/bcd/dataset/test/images/17f5002ee3df64911781868016b10c36.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 53/706 /home/rshah133/bcd/dataset/test/images/18636a03282a86b92f6593607cfce29f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 54/706 /home/rshah133/bcd/dataset/test/images/18b6303a3ede8d3556f87dada8d64c49.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 55/706 /home/rshah133/bcd/dataset/test/images/19189466123f991dfd57d7b963c9c908.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 56/706 /home/rshah133/bcd/dataset/test/images/19269b87da23b12053b3bfcfa65a2eeb.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 57/706 /home/rshah133/bcd/dataset/test/images/198b5967aaa577ad4089badb22689972.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 58/706 /home/rshah133/bcd/dataset/test/images/19c0ecd06984b4d4b2c46812e85a06e6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 59/706 /home/rshah133/bcd/dataset/test/images/1a1a4edb97ee31ebfa7804ccc57d340f.jpg: 1024x1024 3 Masss, 2.3ms\n",
      "image 60/706 /home/rshah133/bcd/dataset/test/images/1a640b603b5e70a42161bfbf42eb21d1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 61/706 /home/rshah133/bcd/dataset/test/images/1a6fc2d6c56e6b1b45d348df8c63c511.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 62/706 /home/rshah133/bcd/dataset/test/images/1a726ea772cfde63af2de1d9d1fba472.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 63/706 /home/rshah133/bcd/dataset/test/images/1a89e1a41d82efe8826ffe15c41db3f4.jpg: 1024x1024 1 Mass, 1 Spiculation, 2.3ms\n",
      "image 64/706 /home/rshah133/bcd/dataset/test/images/1aedd7fc33c55fb511e2dcb7a8493509.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 65/706 /home/rshah133/bcd/dataset/test/images/1b1463c42b11eb981faa5259f2c7b896.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 66/706 /home/rshah133/bcd/dataset/test/images/1b3ea2ffe5dc67d51c493ef22faed9e3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 67/706 /home/rshah133/bcd/dataset/test/images/1bf3336865229b5b85439dc942721a64.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 68/706 /home/rshah133/bcd/dataset/test/images/1c1b9f28c515819a9eb5191e36709d8f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 69/706 /home/rshah133/bcd/dataset/test/images/1c35cb30f776b18ab35a12deae0845b9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 70/706 /home/rshah133/bcd/dataset/test/images/1cfb1d7f513466d8ca7900c23346d309.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 71/706 /home/rshah133/bcd/dataset/test/images/1d136d5f293069a1f77f544cf0f8265b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 72/706 /home/rshah133/bcd/dataset/test/images/1d2d50c66ee2e230c6327076c2fe6d00.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 73/706 /home/rshah133/bcd/dataset/test/images/1d51d5bd22846821409cb531a95979d2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 74/706 /home/rshah133/bcd/dataset/test/images/1d6b62c0ca67fccea012daed532bb9fc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 75/706 /home/rshah133/bcd/dataset/test/images/1d83fd3dfe4a9beb628b030d1d37031b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 76/706 /home/rshah133/bcd/dataset/test/images/1d9dec180a5c2bab3b77e55684cd7f95.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 77/706 /home/rshah133/bcd/dataset/test/images/1dda87c5adb8efb52c1e559ea4cabf54.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 78/706 /home/rshah133/bcd/dataset/test/images/1ddb3b37690c98df094920a905b880ac.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 79/706 /home/rshah133/bcd/dataset/test/images/1df290db9b7769fabaddab943891889d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 80/706 /home/rshah133/bcd/dataset/test/images/1dfc7b08356eb6265b16a51a1ea208b1.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 81/706 /home/rshah133/bcd/dataset/test/images/1e074d67076ab3ccbcb6fabb7a93e479.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 82/706 /home/rshah133/bcd/dataset/test/images/1e2d94424f5a9a847f1a7e8eae1ecdd7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 83/706 /home/rshah133/bcd/dataset/test/images/1e6d951c061c1e68ca0056aa7af70405.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 84/706 /home/rshah133/bcd/dataset/test/images/1e7ad5577c2f5e49294f9c3660968910.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 85/706 /home/rshah133/bcd/dataset/test/images/1eaafc26e519dcbb2f561902d3b6af85.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 86/706 /home/rshah133/bcd/dataset/test/images/1edafb4bb142562da9c6d0ebba585b83.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 87/706 /home/rshah133/bcd/dataset/test/images/1edfbc7b48a507046042a9961755af6a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 88/706 /home/rshah133/bcd/dataset/test/images/1f2ad3de97b6d7a4d8f78af09c11b580.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 89/706 /home/rshah133/bcd/dataset/test/images/1f4e4c2039476a9884bdd84c20d1484f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 90/706 /home/rshah133/bcd/dataset/test/images/1f7105d923abab8db6a92eaa796dea1b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 91/706 /home/rshah133/bcd/dataset/test/images/1f741efcce7da5f4fcc10378eeeab159.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 92/706 /home/rshah133/bcd/dataset/test/images/1f7810314e30e081e2d81ddb34019cc4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 93/706 /home/rshah133/bcd/dataset/test/images/1fbf74aa3e9be948b0e9b1e73f8b3a9b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 94/706 /home/rshah133/bcd/dataset/test/images/1fc6c25e3832f3dbabe0d9e9dc85602f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 95/706 /home/rshah133/bcd/dataset/test/images/1fdb46d59513d90e8e1750799d9f8d03.jpg: 1024x1024 2 Masss, 3 Spiculations, 2.3ms\n",
      "image 96/706 /home/rshah133/bcd/dataset/test/images/1ffb933b38767a155e5afc94d852bd5b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 97/706 /home/rshah133/bcd/dataset/test/images/202d1c29785f6327985ffda7100e2265.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 98/706 /home/rshah133/bcd/dataset/test/images/20ac518bf6370bc7c2b1adcf7377def8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 99/706 /home/rshah133/bcd/dataset/test/images/20dfb3774ef8e9ee1fa642dfab995292.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 100/706 /home/rshah133/bcd/dataset/test/images/20e22b55458ddc1002871f0b10bc0c91.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 101/706 /home/rshah133/bcd/dataset/test/images/20ef0abde078ddde96b03ddb3608e3ec.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 102/706 /home/rshah133/bcd/dataset/test/images/212bc03533346819d0c6d449d631f69f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 103/706 /home/rshah133/bcd/dataset/test/images/215186ee75b38c34499cd0ebadc7ed20.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 104/706 /home/rshah133/bcd/dataset/test/images/2167f4da549862d60f43782cd38fb8ae.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 105/706 /home/rshah133/bcd/dataset/test/images/216d7c52e6a86ab26e19b06dac26351c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 106/706 /home/rshah133/bcd/dataset/test/images/219cc02d369ac35c640f01515fd18704.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 107/706 /home/rshah133/bcd/dataset/test/images/21a78229489f5b35b0b037f678a5cac4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 108/706 /home/rshah133/bcd/dataset/test/images/21bf6d9fd0dff22dc2b4fa769f2c5b6f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 109/706 /home/rshah133/bcd/dataset/test/images/21f6ff86237974dfe61a77e84b77c5c0.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 110/706 /home/rshah133/bcd/dataset/test/images/2205fbb6b2e8a942bd796fa0e4d53f61.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 111/706 /home/rshah133/bcd/dataset/test/images/2239d320d35b1d7ee84c9ad5bc692096.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 112/706 /home/rshah133/bcd/dataset/test/images/225f1e3b1aa1c243f6477229cfe2e81d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 113/706 /home/rshah133/bcd/dataset/test/images/228bbafbc7cd167675e4d534785a56ef.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 114/706 /home/rshah133/bcd/dataset/test/images/22fba1258f27256a9f1d090b0ddca9c7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 115/706 /home/rshah133/bcd/dataset/test/images/2311c127704c6b0cf325d4da697d2b26.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 116/706 /home/rshah133/bcd/dataset/test/images/232d42e92fc9445b6e882d8391c3c782.jpg: 1024x1024 1 Mass, 2 Spiculations, 2.4ms\n",
      "image 117/706 /home/rshah133/bcd/dataset/test/images/233ca7084a75a79608f0225653bf0d83.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 118/706 /home/rshah133/bcd/dataset/test/images/23470268f47f1ea61977bf70392e3dc0.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 119/706 /home/rshah133/bcd/dataset/test/images/23b6b19763d617991f1fdaa4cab135c4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 120/706 /home/rshah133/bcd/dataset/test/images/2424a42cd4c30fdb50d63a044055b1ee.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 121/706 /home/rshah133/bcd/dataset/test/images/24554a4f939d8c4ec6f710ac98385407.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 122/706 /home/rshah133/bcd/dataset/test/images/2461b5dd3a59b501aaea002ab61050f5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 123/706 /home/rshah133/bcd/dataset/test/images/248979f8c341862b99d2ab1e40a4efb1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 124/706 /home/rshah133/bcd/dataset/test/images/24ab640532fbe99e1de51aa6ab9697ba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 125/706 /home/rshah133/bcd/dataset/test/images/26b97f0b7e0c45b51a4a26a0390168e0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 126/706 /home/rshah133/bcd/dataset/test/images/271e8bfd46adee65f8580092753d08e5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 127/706 /home/rshah133/bcd/dataset/test/images/27d9bf4e5b772624325d6232ffc8378a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 128/706 /home/rshah133/bcd/dataset/test/images/27f066be252acf8b8be0e058e30b3a1a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 129/706 /home/rshah133/bcd/dataset/test/images/298aba8110e3e2667be23e7f8d188f44.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 130/706 /home/rshah133/bcd/dataset/test/images/2b5cec9cad04a6c5eaf1cd2ec2e7a6f2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 131/706 /home/rshah133/bcd/dataset/test/images/2bb31d34320c4d1005371802dcac319c.jpg: 1024x1024 1 Mass, 2 Spiculations, 2.3ms\n",
      "image 132/706 /home/rshah133/bcd/dataset/test/images/2ce389a2252ceb3a87a7be9a14721692.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 133/706 /home/rshah133/bcd/dataset/test/images/2daca5fbd617d1a692439c5133e1968d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 134/706 /home/rshah133/bcd/dataset/test/images/2e62eeadcca2218c0aba4f2921a27153.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 135/706 /home/rshah133/bcd/dataset/test/images/2ee7f36fd6e157b40d4f0326f6fcc0d2.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 136/706 /home/rshah133/bcd/dataset/test/images/2ef3b7beac25dd7db4a75e18e9e59d59.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 137/706 /home/rshah133/bcd/dataset/test/images/2f0b2326c2f683baa25cb96d8e05ea64.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 138/706 /home/rshah133/bcd/dataset/test/images/2f11b93c073630fc866ebd61708c49c5.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 139/706 /home/rshah133/bcd/dataset/test/images/2f48022a49d11be37b6b391fbc5bc47c.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 140/706 /home/rshah133/bcd/dataset/test/images/2f51ad43272ff8e8d2070cd4f3763c48.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 141/706 /home/rshah133/bcd/dataset/test/images/2f944efb1cb9579442df2d7fe6a579b7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 142/706 /home/rshah133/bcd/dataset/test/images/2f9a9468e908a35fb3c29fba6ecce60c.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 143/706 /home/rshah133/bcd/dataset/test/images/2feab51140b38f9ec90e17b7006501b2.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 144/706 /home/rshah133/bcd/dataset/test/images/3003a43c012e3e7c754151b4b578f90b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 145/706 /home/rshah133/bcd/dataset/test/images/3047456544795c193f2f5a12db464ced.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 146/706 /home/rshah133/bcd/dataset/test/images/305835a194605ef353a1700def9a2429.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 147/706 /home/rshah133/bcd/dataset/test/images/3063104074c2aa4f5f2b31c7fd2a2040.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 148/706 /home/rshah133/bcd/dataset/test/images/3067b317b88697b45e336a9e1a481021.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 149/706 /home/rshah133/bcd/dataset/test/images/30caea823462601262e5d393e6d0312a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 150/706 /home/rshah133/bcd/dataset/test/images/313c8967c8e806bb1bbc738f1469d133.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 151/706 /home/rshah133/bcd/dataset/test/images/31573a0308d41e44ed826b9a15e6af94.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 152/706 /home/rshah133/bcd/dataset/test/images/31b7ac12bfdae5f0a7b484464aaba81c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 153/706 /home/rshah133/bcd/dataset/test/images/31ccd1481d89aa41bddf4a66c7a5c007.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 154/706 /home/rshah133/bcd/dataset/test/images/31fcc94f3079f2b234c6e4304ab540e3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 155/706 /home/rshah133/bcd/dataset/test/images/3249215304caf281062d80f4b3798634.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 156/706 /home/rshah133/bcd/dataset/test/images/3350de5a7aea26467719ebd8c9153fb6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 157/706 /home/rshah133/bcd/dataset/test/images/338460bf0c6de576629169b75370964b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 158/706 /home/rshah133/bcd/dataset/test/images/33e09329292305dcb0495cd24e4e934d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 159/706 /home/rshah133/bcd/dataset/test/images/33ef0769c0bbda92028dd40d73a2bfae.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 160/706 /home/rshah133/bcd/dataset/test/images/349182b392578ba8f9d8bbffeef955e3.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 161/706 /home/rshah133/bcd/dataset/test/images/35293500d91fb681fd8ff9171d8161c1.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 162/706 /home/rshah133/bcd/dataset/test/images/360a2637d08a1b3f8fef4f3a3e14e717.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 163/706 /home/rshah133/bcd/dataset/test/images/36f1d0a7b515cef7eab05bdbfde38094.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 164/706 /home/rshah133/bcd/dataset/test/images/370f48157f08675de0b49988b7c39622.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 165/706 /home/rshah133/bcd/dataset/test/images/37448b35920f755460e8066643add226.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 166/706 /home/rshah133/bcd/dataset/test/images/37a23b32dea999c01e4bc46901b21d67.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 167/706 /home/rshah133/bcd/dataset/test/images/389e63a564ab355b88c8ec7391a11069.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 168/706 /home/rshah133/bcd/dataset/test/images/3920b4311fa5b13f5a2c9185156ae9d5.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 169/706 /home/rshah133/bcd/dataset/test/images/39b4736d81cf35512313a70cc8375269.jpg: 1024x1024 1 Mass, 5 Spiculations, 2.4ms\n",
      "image 170/706 /home/rshah133/bcd/dataset/test/images/39f3ef0e8046a9b4e6c81262d634053d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 171/706 /home/rshah133/bcd/dataset/test/images/3a5599f4f1f55e7a83385c46a3c29885.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 172/706 /home/rshah133/bcd/dataset/test/images/3a6dffa30940fa8f5e115a9888eae9e8.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 173/706 /home/rshah133/bcd/dataset/test/images/3b376a343a6032c3450154820517e90d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 174/706 /home/rshah133/bcd/dataset/test/images/3bb3b2b2842c76b37df73a4efcea25ba.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 175/706 /home/rshah133/bcd/dataset/test/images/3bee0f712a17866762153fc376b241ea.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 176/706 /home/rshah133/bcd/dataset/test/images/3c315903764b853c05c059346675e1b7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 177/706 /home/rshah133/bcd/dataset/test/images/3c48d1eac361faa8b2ec575dba6bcd4e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 178/706 /home/rshah133/bcd/dataset/test/images/3de1a9c60e55cae229c112cd3d7577ce.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 179/706 /home/rshah133/bcd/dataset/test/images/3e87afa0f8da27f58d69338173dbbcf6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 180/706 /home/rshah133/bcd/dataset/test/images/3f43a204d38e938ddc1f5832c508ad1e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 181/706 /home/rshah133/bcd/dataset/test/images/408e8d491fcc74612a291e9579d9bbad.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 182/706 /home/rshah133/bcd/dataset/test/images/42670b1f3b20518b71e9ae297859ccf1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 183/706 /home/rshah133/bcd/dataset/test/images/4274a76dcc9e28508eff58acc103dc73.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 184/706 /home/rshah133/bcd/dataset/test/images/42f76304c7825a09405739d899c6cd86.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 185/706 /home/rshah133/bcd/dataset/test/images/43361e8af5bd4f6a17194ad97b57c4f9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 186/706 /home/rshah133/bcd/dataset/test/images/43a32df43087ababd713b27ab53f2632.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 187/706 /home/rshah133/bcd/dataset/test/images/4459e5a3c47ab8d6e79d80cf198d60f2.jpg: 1024x1024 2 Masss, 1 Spiculation, 2.3ms\n",
      "image 188/706 /home/rshah133/bcd/dataset/test/images/46d9c0dced48fa61647ce80db623491e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 189/706 /home/rshah133/bcd/dataset/test/images/4723b2edfcdeae22f045ec580e73e1c6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 190/706 /home/rshah133/bcd/dataset/test/images/4729d422042d543e3deb79bc9bad8ab2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 191/706 /home/rshah133/bcd/dataset/test/images/4872fe367cd03b30b0da74d7aabb9ae7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 192/706 /home/rshah133/bcd/dataset/test/images/48d0e802edd6506cf5549db3f09b3c4a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 193/706 /home/rshah133/bcd/dataset/test/images/491dccc55dfaad63b0d2eaf6fc7daa8b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 194/706 /home/rshah133/bcd/dataset/test/images/49cf189f3a033a24396459793ad27017.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 195/706 /home/rshah133/bcd/dataset/test/images/49ef5e8188be5318bcca7a7e26fdd4b7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 196/706 /home/rshah133/bcd/dataset/test/images/49f860ced6222146c04dd74355255abf.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 197/706 /home/rshah133/bcd/dataset/test/images/4a06e41e38450e4c6e743b8e8da1ec60.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 198/706 /home/rshah133/bcd/dataset/test/images/4a965d6864934c82cc2829ffbf42acd6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 199/706 /home/rshah133/bcd/dataset/test/images/4a97666bfc0fcacbe5509c2bfd9368e9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 200/706 /home/rshah133/bcd/dataset/test/images/4ae52d114924c90767dfb6ab86ea460d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 201/706 /home/rshah133/bcd/dataset/test/images/4b9618d7a794a67ec6b53a187254b700.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 202/706 /home/rshah133/bcd/dataset/test/images/4bedc4697d4a92230ba840a09c82d590.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 203/706 /home/rshah133/bcd/dataset/test/images/4c3a8a7db202ea367baca51aa5b3b6d5.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 204/706 /home/rshah133/bcd/dataset/test/images/4d1d2cd40d8db9f452bd1b01771c1f9a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 205/706 /home/rshah133/bcd/dataset/test/images/4d59a1f3bc1183b998c28b18f531fb9d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 206/706 /home/rshah133/bcd/dataset/test/images/4d96d394fe4b20778014bdde96b5d34e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 207/706 /home/rshah133/bcd/dataset/test/images/4dd908b41dbb97c46b7a8127ef88a647.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 208/706 /home/rshah133/bcd/dataset/test/images/4efef828cbd9e843c82fd5028389b3ae.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 209/706 /home/rshah133/bcd/dataset/test/images/4f0b75a4d53ebd31eb54d68f03eb44a2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 210/706 /home/rshah133/bcd/dataset/test/images/4f1f57e071d6dc46b920f3e0da77e9ec.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 211/706 /home/rshah133/bcd/dataset/test/images/4f48e40a18772bc74164f3d915474114.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 212/706 /home/rshah133/bcd/dataset/test/images/5054046e40bc6da524e7e8beaa6f115f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 213/706 /home/rshah133/bcd/dataset/test/images/509310f050909df752c2f63c4ab4f750.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 214/706 /home/rshah133/bcd/dataset/test/images/510552a160e46b33a48b8c523568827b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 215/706 /home/rshah133/bcd/dataset/test/images/5114c128f347d8708753f229cfa34531.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 216/706 /home/rshah133/bcd/dataset/test/images/519e1a01bd3c08ad8a46fc476730ca0c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 217/706 /home/rshah133/bcd/dataset/test/images/51b47f9024ccad1356354f56ac916f29.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 218/706 /home/rshah133/bcd/dataset/test/images/5247f45a2df0076686e2737a1a63e407.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 219/706 /home/rshah133/bcd/dataset/test/images/52750d0cf16931d9f09530901041a345.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 220/706 /home/rshah133/bcd/dataset/test/images/52b403c5c51efa04629aebd1629bd1a5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 221/706 /home/rshah133/bcd/dataset/test/images/5303d45e31ed5f069964b4c47a0f1b55.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 222/706 /home/rshah133/bcd/dataset/test/images/53f6139f06e3efdb61d1ec6e1f1e6982.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 223/706 /home/rshah133/bcd/dataset/test/images/5420f34131041364bf3d65b35bb86175.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 224/706 /home/rshah133/bcd/dataset/test/images/547ad63495fe93f02cc49c9d7590794c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 225/706 /home/rshah133/bcd/dataset/test/images/54aa2758fbda627d811412679d95fb22.jpg: 1024x1024 2 Masss, 2 Spiculations, 2.3ms\n",
      "image 226/706 /home/rshah133/bcd/dataset/test/images/54cdbb11f9da7660575eef584b9ce520.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 227/706 /home/rshah133/bcd/dataset/test/images/54d0efb124cfa5d783b2ad5f074608e1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 228/706 /home/rshah133/bcd/dataset/test/images/54f8dce3a645c0e7b8cfa789f313d11f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 229/706 /home/rshah133/bcd/dataset/test/images/551162489fd5e6b59336fc1eee7b7021.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 230/706 /home/rshah133/bcd/dataset/test/images/557a2c3c6d82872584e701efecda7d0f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 231/706 /home/rshah133/bcd/dataset/test/images/56030132cd20bbf82075392b8dca6405.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 232/706 /home/rshah133/bcd/dataset/test/images/569438811d4355ce1f2fe24256d6b597.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 233/706 /home/rshah133/bcd/dataset/test/images/56fc4476e431eac2f1bc6291b9c78210.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 234/706 /home/rshah133/bcd/dataset/test/images/56fe870f46d9f4862df7cb81de2ddd17.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 235/706 /home/rshah133/bcd/dataset/test/images/5700469390ec03e4f272a766a5cd6732.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 236/706 /home/rshah133/bcd/dataset/test/images/57074dce833587f29bf7218d39fcc773.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 237/706 /home/rshah133/bcd/dataset/test/images/575ecc0d24a2fd3d224b2cdf1837947e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 238/706 /home/rshah133/bcd/dataset/test/images/5765fc3b2a44f33c127621b8f744425e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 239/706 /home/rshah133/bcd/dataset/test/images/577ebd19f81487527b8c55694b1e6a59.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 240/706 /home/rshah133/bcd/dataset/test/images/58217abebc96c95c94cb204d5cc408cd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 241/706 /home/rshah133/bcd/dataset/test/images/58a92ed8d1f8fecfce0f9d578a9937fe.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 242/706 /home/rshah133/bcd/dataset/test/images/596a7f8bf2e64df0766de379086f84c9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 243/706 /home/rshah133/bcd/dataset/test/images/59cdcc53f76f8c12741f7770d8fb372d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 244/706 /home/rshah133/bcd/dataset/test/images/5a172903c1060312fd48a5e37a945d50.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 245/706 /home/rshah133/bcd/dataset/test/images/5b34564ccb99b6ef4e858015ee58b49e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 246/706 /home/rshah133/bcd/dataset/test/images/5babc8f7e8ede530d3f9229cc1d1548e.jpg: 1024x1024 3 Spiculations, 2.3ms\n",
      "image 247/706 /home/rshah133/bcd/dataset/test/images/5bf1fb6fb072221239f84b1dc86ad112.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 248/706 /home/rshah133/bcd/dataset/test/images/5c2ed994f27089b2d48977790fce829b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 249/706 /home/rshah133/bcd/dataset/test/images/5cd330a56ea7c77a1fa1181712966dbf.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 250/706 /home/rshah133/bcd/dataset/test/images/5d13674e2ed04208bf232e2eeb468f7a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 251/706 /home/rshah133/bcd/dataset/test/images/5fc6502972be29b0ea256281cd69e804.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 252/706 /home/rshah133/bcd/dataset/test/images/5fdf0b41752d8b15dfd523053858da2e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 253/706 /home/rshah133/bcd/dataset/test/images/5fe8350c930a08ebc532cbb304f5642a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 254/706 /home/rshah133/bcd/dataset/test/images/614ee08af2499715e2b20b97d387fd92.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 255/706 /home/rshah133/bcd/dataset/test/images/61639cfff95dae27b1a9953fbb7b4339.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 256/706 /home/rshah133/bcd/dataset/test/images/61755c4437985c8f56b6d5a3734d534b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 257/706 /home/rshah133/bcd/dataset/test/images/619c3641bad6cc105b32173c3e0747cb.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 258/706 /home/rshah133/bcd/dataset/test/images/61dea424b31908763e86ddb3e420e007.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 259/706 /home/rshah133/bcd/dataset/test/images/625aa350502a7038cfe5f9ca5f1a65f4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 260/706 /home/rshah133/bcd/dataset/test/images/626d9144ab105af67e6ab1b00397531a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 261/706 /home/rshah133/bcd/dataset/test/images/627af26717c682a07770173c71b4c17e.jpg: 1024x1024 1 Spiculation, 2.4ms\n",
      "image 262/706 /home/rshah133/bcd/dataset/test/images/62bee7e64437d079c4cccf0b5293240f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 263/706 /home/rshah133/bcd/dataset/test/images/62f8a16b3e780f015c1ba48c7c98f184.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 264/706 /home/rshah133/bcd/dataset/test/images/63857e01d707240c042dd951cffb43de.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 265/706 /home/rshah133/bcd/dataset/test/images/63a6fea3ac77af3f8e332371745ccd65.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 266/706 /home/rshah133/bcd/dataset/test/images/63f4053da6b026f6b58b159fdf79b6ab.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 267/706 /home/rshah133/bcd/dataset/test/images/63fc9a74c6faa9ea7a869fe657201e70.jpg: 1024x1024 1 Mass, 2.4ms\n",
      "image 268/706 /home/rshah133/bcd/dataset/test/images/6450616fa854fa9d7a26d111e880792e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 269/706 /home/rshah133/bcd/dataset/test/images/64e88bc3716211bb2fc5dae3ca9e5b92.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 270/706 /home/rshah133/bcd/dataset/test/images/6559b8de9d345fd8b234329f27659f99.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 271/706 /home/rshah133/bcd/dataset/test/images/6564d2c57d2f23c96d73cc6f21ec78bb.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 272/706 /home/rshah133/bcd/dataset/test/images/65ece004ffc7a5d3b472b0ff63c02680.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 273/706 /home/rshah133/bcd/dataset/test/images/660d6f19556bd5eab8d81c40150c2ba0.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 274/706 /home/rshah133/bcd/dataset/test/images/665f9100c1aa11d51aac07a1ac35ed2f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 275/706 /home/rshah133/bcd/dataset/test/images/66d392ec44df82ac333d01411a01679d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 276/706 /home/rshah133/bcd/dataset/test/images/67190a4e7edcef162645acee9e14db4c.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 277/706 /home/rshah133/bcd/dataset/test/images/671b8217de35176be9831fffe78ffb28.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 278/706 /home/rshah133/bcd/dataset/test/images/679a6515593f9692eb6a622b7b6b0aa0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 279/706 /home/rshah133/bcd/dataset/test/images/683abf5002cb766e0d5430fbb25c2b1e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 280/706 /home/rshah133/bcd/dataset/test/images/68ba2f79b2cbffecb3512279a6879fc7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 281/706 /home/rshah133/bcd/dataset/test/images/68f20f74834772788a9f9350b0492fb6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 282/706 /home/rshah133/bcd/dataset/test/images/6943cda7ce5b1cdf56ea8fffb17c52f5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 283/706 /home/rshah133/bcd/dataset/test/images/695eb015c1143034838b1f25672d458a.jpg: 1024x1024 2 Masss, 2 Spiculations, 2.3ms\n",
      "image 284/706 /home/rshah133/bcd/dataset/test/images/69b872a225cb0e218a26a8a313ee3ef4.jpg: 1024x1024 1 Mass, 3 Spiculations, 2.3ms\n",
      "image 285/706 /home/rshah133/bcd/dataset/test/images/6aad41f7488e1ef6d9f422345c6618ba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 286/706 /home/rshah133/bcd/dataset/test/images/6ab2f8643bffd0c603fdb15f66f9ff3c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 287/706 /home/rshah133/bcd/dataset/test/images/6b180003def75a5e79fb66a9c789d069.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 288/706 /home/rshah133/bcd/dataset/test/images/6b86549dd6a1f6871be9e29eefae2fd8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 289/706 /home/rshah133/bcd/dataset/test/images/6c27e1331b4f46e645d03e4e17698299.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 290/706 /home/rshah133/bcd/dataset/test/images/6c5ba6a34d007bceeccba36666c74ab0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 291/706 /home/rshah133/bcd/dataset/test/images/6c89a90416411eecf56e5ea1fff2a1e2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 292/706 /home/rshah133/bcd/dataset/test/images/6caa0cd509e3656be7e3c0c0cb3b7104.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 293/706 /home/rshah133/bcd/dataset/test/images/6cab0db67458b7c2bf4afade630adee5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 294/706 /home/rshah133/bcd/dataset/test/images/6d04b0e2eecf3dcfd92ba285c28b5a72.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 295/706 /home/rshah133/bcd/dataset/test/images/6d9dc7a5dd8bdbe82eceb4424ca04cf5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 296/706 /home/rshah133/bcd/dataset/test/images/6dcaebaf5ca9c97b8b8cf23720751ba1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 297/706 /home/rshah133/bcd/dataset/test/images/6e0cfd8cdae637f4613868dbbc34b453.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 298/706 /home/rshah133/bcd/dataset/test/images/6e66c1b763178000c4742194dda4f8ad.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 299/706 /home/rshah133/bcd/dataset/test/images/6ec73d7e74c73265c4f9ed781ccecd71.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 300/706 /home/rshah133/bcd/dataset/test/images/6f858d4db04378848c0f4f4dd9527004.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 301/706 /home/rshah133/bcd/dataset/test/images/6f8e34d9a3a750468528290d5813eb1a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 302/706 /home/rshah133/bcd/dataset/test/images/6f9e49fc60bf2191b109b84f136089ef.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 303/706 /home/rshah133/bcd/dataset/test/images/6fa1786279e64980d80a34a88722836c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 304/706 /home/rshah133/bcd/dataset/test/images/6fce44a9101a0851e8057e2d36339c17.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 305/706 /home/rshah133/bcd/dataset/test/images/7009b2522f79bc2dd81f2a311bce7914.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 306/706 /home/rshah133/bcd/dataset/test/images/700d65782e684be66b823b388366620e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 307/706 /home/rshah133/bcd/dataset/test/images/703b37d21eca25ae7ca8060178eefb24.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 308/706 /home/rshah133/bcd/dataset/test/images/711477c4914b858fbb9bd62b9def1b3a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 309/706 /home/rshah133/bcd/dataset/test/images/71e9f15a78cc250cf93865859f7ef372.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 310/706 /home/rshah133/bcd/dataset/test/images/723ba02a1a301b9e6e3689e4a349a32f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 311/706 /home/rshah133/bcd/dataset/test/images/72423f5fe30fe6377c15d1331761d594.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 312/706 /home/rshah133/bcd/dataset/test/images/726355704c0328a581f9182fee4d198f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 313/706 /home/rshah133/bcd/dataset/test/images/726e579eb8982c5fb3c120039a64fe01.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 314/706 /home/rshah133/bcd/dataset/test/images/72711c5c352ad731d4f832d693af1e8d.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 315/706 /home/rshah133/bcd/dataset/test/images/729fae337639d825ca83e563c6efedc6.jpg: 1024x1024 1 Mass, 2.4ms\n",
      "image 316/706 /home/rshah133/bcd/dataset/test/images/72b7dfd519a57a683f740df8cde06ece.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 317/706 /home/rshah133/bcd/dataset/test/images/72eb142a93824b699fa99fc265ea158a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 318/706 /home/rshah133/bcd/dataset/test/images/7323314998471cde47c6fba70ae6d32c.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 319/706 /home/rshah133/bcd/dataset/test/images/735851f234a657318773c4cbbe4969cf.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 320/706 /home/rshah133/bcd/dataset/test/images/7385e8cf7b29764525c81de4aa1aebe4.jpg: 1024x1024 1 Mass, 7 Spiculations, 2.4ms\n",
      "image 321/706 /home/rshah133/bcd/dataset/test/images/73903959dfe4f3c40cb6f0365945099a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 322/706 /home/rshah133/bcd/dataset/test/images/73c2ae4ae3de4d2832fd3e55b0336b97.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 323/706 /home/rshah133/bcd/dataset/test/images/73d20cbf87ec2637a3de9d950ad809b2.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 324/706 /home/rshah133/bcd/dataset/test/images/73d9a9cb6d8d2685271440b9bd0bfc4b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 325/706 /home/rshah133/bcd/dataset/test/images/73dcab1172639ae173f533e072daf2a4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 326/706 /home/rshah133/bcd/dataset/test/images/73ed34f1fd373ef738250816bc26a862.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 327/706 /home/rshah133/bcd/dataset/test/images/73fb935853a4c56c41e9b83fb05caf84.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 328/706 /home/rshah133/bcd/dataset/test/images/75065fad738a275c9c27526ea71a14b9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 329/706 /home/rshah133/bcd/dataset/test/images/758f244ee63b11692fa627ce500852b9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 330/706 /home/rshah133/bcd/dataset/test/images/75dca2f372e9a594e1798edd09c44bf9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 331/706 /home/rshah133/bcd/dataset/test/images/75dfd2697f4c53ff02f66d537144e1e3.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 332/706 /home/rshah133/bcd/dataset/test/images/75f0f091a9dc057a428db5761eff3475.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 333/706 /home/rshah133/bcd/dataset/test/images/767f72e2635ddf53b940ade1732aba03.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 334/706 /home/rshah133/bcd/dataset/test/images/76a00a3b38f9db17333f89eb66db5ea6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 335/706 /home/rshah133/bcd/dataset/test/images/76b909c5601fe92762a1d85395a9c54b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 336/706 /home/rshah133/bcd/dataset/test/images/76ba1ecb6e84a2bcb9cad67dbd21f9e4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 337/706 /home/rshah133/bcd/dataset/test/images/76bfc1fd58e796dc262d8980ef37c1f0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 338/706 /home/rshah133/bcd/dataset/test/images/7707710e30c68433968b95e580cdc997.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 339/706 /home/rshah133/bcd/dataset/test/images/797db63f4b3f835684ac457ad3b99d26.jpg: 1024x1024 1 Mass, 4 Spiculations, 2.3ms\n",
      "image 340/706 /home/rshah133/bcd/dataset/test/images/7a6c57ce6034053ca02a8cd32549db7f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 341/706 /home/rshah133/bcd/dataset/test/images/7ac7cad604cfebfa020d065f545037d4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 342/706 /home/rshah133/bcd/dataset/test/images/7bdac3e818c711424019bd0178c9b651.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 343/706 /home/rshah133/bcd/dataset/test/images/7c4891b5d07df8817a24947c8ef613ce.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 344/706 /home/rshah133/bcd/dataset/test/images/7cc5d629c947dae4491227c374fde538.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 345/706 /home/rshah133/bcd/dataset/test/images/7d1ef16add2078608b529209d9d34299.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 346/706 /home/rshah133/bcd/dataset/test/images/7d3a1bc23d6d0eb3a845684039c65c0e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 347/706 /home/rshah133/bcd/dataset/test/images/7d642cca9647103a993d4b3f9e6be393.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 348/706 /home/rshah133/bcd/dataset/test/images/7e279279174120a7bd49d2e142c0bac6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 349/706 /home/rshah133/bcd/dataset/test/images/7e2ac68b81c14f458e7323f2f8951cf2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 350/706 /home/rshah133/bcd/dataset/test/images/7e4cb36605cfe77511eddcdb78312a42.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 351/706 /home/rshah133/bcd/dataset/test/images/7eb213019e972514b4ce6ccb53df509a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 352/706 /home/rshah133/bcd/dataset/test/images/7ec47bb74c9bce6b721cb16aef03accd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 353/706 /home/rshah133/bcd/dataset/test/images/7ece4f330d1b059a4d26d74d6e8db3ba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 354/706 /home/rshah133/bcd/dataset/test/images/801865ddfa426b09cfe44edd40c6179b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 355/706 /home/rshah133/bcd/dataset/test/images/80440acf117f4cecd3ac74097adc8101.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 356/706 /home/rshah133/bcd/dataset/test/images/80782a78ce39bae561649b1d95df085b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 357/706 /home/rshah133/bcd/dataset/test/images/80a19174eea887c90779fc040405258f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 358/706 /home/rshah133/bcd/dataset/test/images/80ae11a78bfd7c9598138c82cd756ad3.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 359/706 /home/rshah133/bcd/dataset/test/images/80c1af9936f6939a0b152736bb3bef58.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 360/706 /home/rshah133/bcd/dataset/test/images/80d1c8b91477afa2378cbfc7f1266dac.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 361/706 /home/rshah133/bcd/dataset/test/images/8205786e592bdcab2587481ffa1b350b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 362/706 /home/rshah133/bcd/dataset/test/images/82447e23ecca920582902149e966b3b6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 363/706 /home/rshah133/bcd/dataset/test/images/82653664152b8c77f16c0dfc63105dad.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 364/706 /home/rshah133/bcd/dataset/test/images/8276c80b48179cae6a896ef161cad385.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 365/706 /home/rshah133/bcd/dataset/test/images/829cbbdd27eed0a50c728b7a5f2b0683.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 366/706 /home/rshah133/bcd/dataset/test/images/82bc1e785dc256a54029ec9bd4327f68.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 367/706 /home/rshah133/bcd/dataset/test/images/82ce050e4866fc273dd87e0a7498c0da.jpg: 1024x1024 1 Mass, 6 Spiculations, 2.3ms\n",
      "image 368/706 /home/rshah133/bcd/dataset/test/images/834e9a35cdc92f2c45e31e80f9cc8ce0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 369/706 /home/rshah133/bcd/dataset/test/images/83be060130997ca7b67b3979978a5d29.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 370/706 /home/rshah133/bcd/dataset/test/images/841802bee1fc1a6b4bde97a754713da8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 371/706 /home/rshah133/bcd/dataset/test/images/847d82f41872e77590bb7cde05a60fcd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 372/706 /home/rshah133/bcd/dataset/test/images/84f451b4a008e729604feb03179090e6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 373/706 /home/rshah133/bcd/dataset/test/images/853dbdcfe62f7b59f725866edf1d03c9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 374/706 /home/rshah133/bcd/dataset/test/images/8544f5b224566c38928fd793d2f5870a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 375/706 /home/rshah133/bcd/dataset/test/images/85942db8feddc69a71df112fabaeda92.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 376/706 /home/rshah133/bcd/dataset/test/images/85a4f486bd40d8c462887a45c08e0715.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 377/706 /home/rshah133/bcd/dataset/test/images/86048af83b217cbc59cfa9d51af09696.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 378/706 /home/rshah133/bcd/dataset/test/images/8625c888c8bdfc650c4c2eba665accc2.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 379/706 /home/rshah133/bcd/dataset/test/images/862e22b040bf23946e96da765f9871c1.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 380/706 /home/rshah133/bcd/dataset/test/images/86ab85b00f60d2d8e238594886880438.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 381/706 /home/rshah133/bcd/dataset/test/images/86d16a47cfcb661ae42790626f4df712.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 382/706 /home/rshah133/bcd/dataset/test/images/870ec0cc5a1b1874d8c972a8595f41a2.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 383/706 /home/rshah133/bcd/dataset/test/images/873ab15ec29cd51a27d104be8947aec9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 384/706 /home/rshah133/bcd/dataset/test/images/875cf45e7952e6bd9b2ef7ed0df5259f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 385/706 /home/rshah133/bcd/dataset/test/images/87f0ee76b74975a33b718a41b32d70c9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 386/706 /home/rshah133/bcd/dataset/test/images/891295e2c553da37d37c76b463f1231c.jpg: 1024x1024 2 Spiculations, 2.3ms\n",
      "image 387/706 /home/rshah133/bcd/dataset/test/images/891e28e29869d732f25d8763a6823e07.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 388/706 /home/rshah133/bcd/dataset/test/images/89537aa9ac593c57e7375f1572e3e773.jpg: 1024x1024 3 Masss, 2.3ms\n",
      "image 389/706 /home/rshah133/bcd/dataset/test/images/895919f94d2054826bc04c14f45f080c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 390/706 /home/rshah133/bcd/dataset/test/images/8992c148694c07d13f2e0ae1c80a15f8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 391/706 /home/rshah133/bcd/dataset/test/images/89c3dd3095a646213c280c180094d87f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 392/706 /home/rshah133/bcd/dataset/test/images/8a7414f4289d4ffdfae1c8c6b767a4ef.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 393/706 /home/rshah133/bcd/dataset/test/images/8ab5422aeb3e0e4ca42633e70da0508e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 394/706 /home/rshah133/bcd/dataset/test/images/8ae348f705feb1dae2aa587c7d374813.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 395/706 /home/rshah133/bcd/dataset/test/images/8af12ad744f6e5b0d7f6cf94a30755ea.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 396/706 /home/rshah133/bcd/dataset/test/images/8b8a5fc22981d783644c15594185f295.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 397/706 /home/rshah133/bcd/dataset/test/images/8bd6f0c10da77a15a1cd6d2ab6fd65a6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 398/706 /home/rshah133/bcd/dataset/test/images/8c799782afb5ab3a1a9cd5236dbddb98.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 399/706 /home/rshah133/bcd/dataset/test/images/8c8f1870ec508423e1a91f4fb426d9d8.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 400/706 /home/rshah133/bcd/dataset/test/images/8c91dd4b7b90a82ea2f89627d2f67092.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 401/706 /home/rshah133/bcd/dataset/test/images/8cf6ce9707a45986000b816af94d3087.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 402/706 /home/rshah133/bcd/dataset/test/images/8ed0618edab59a40763a118c052a52ba.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 403/706 /home/rshah133/bcd/dataset/test/images/8ee444c21b4152204f05ef7b5358005f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 404/706 /home/rshah133/bcd/dataset/test/images/9076323f4b661b4b57a9229b869c62c7.jpg: 1024x1024 1 Mass, 1 Spiculation, 2.4ms\n",
      "image 405/706 /home/rshah133/bcd/dataset/test/images/91b56dab8873e1bf56a4ade2b0d02fba.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 406/706 /home/rshah133/bcd/dataset/test/images/91f01e407f632c7d2370e5dd106f1c85.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 407/706 /home/rshah133/bcd/dataset/test/images/93960b56ba5808e9047aff73cf9b0762.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 408/706 /home/rshah133/bcd/dataset/test/images/941b68f8b8efaca561da90adea3d4760.jpg: 1024x1024 1 Spiculation, 2.4ms\n",
      "image 409/706 /home/rshah133/bcd/dataset/test/images/9482a0d32b85123f738360855c2a3a3a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 410/706 /home/rshah133/bcd/dataset/test/images/94d8142612eafdc9533dc85e0553c4f8.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 411/706 /home/rshah133/bcd/dataset/test/images/94ded0fb1036a6f4f044beba047b8d3a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 412/706 /home/rshah133/bcd/dataset/test/images/94e4d888c947abda8f191f8f74e5d7bc.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 413/706 /home/rshah133/bcd/dataset/test/images/9515868b0e0de7195161d62e0f580dcc.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 414/706 /home/rshah133/bcd/dataset/test/images/952db864c34b4f02eeabc1559fda2058.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 415/706 /home/rshah133/bcd/dataset/test/images/9542fd8c2f9230690935e659b491c6de.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 416/706 /home/rshah133/bcd/dataset/test/images/95fc8c105d16ac569c2a2ac2966e8c55.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 417/706 /home/rshah133/bcd/dataset/test/images/96b378f0fbde6e8d9cf37825fb4b29bf.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 418/706 /home/rshah133/bcd/dataset/test/images/96eb9c4bdf059f2f8da825bfc0a3ba69.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 419/706 /home/rshah133/bcd/dataset/test/images/972165237ce4c410eb9d612a1dc51a43.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 420/706 /home/rshah133/bcd/dataset/test/images/9732a0b8ade2ad8495a0598890d15149.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 421/706 /home/rshah133/bcd/dataset/test/images/97b36b94a940b61017d4dd6cbbf5b8fc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 422/706 /home/rshah133/bcd/dataset/test/images/9992a1941e974a38b391b2a5fa78e6c6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 423/706 /home/rshah133/bcd/dataset/test/images/99b304a3e368041ed3674dd654c6cf8c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 424/706 /home/rshah133/bcd/dataset/test/images/9a7b29e942f19636ffcc7562e9ca91bc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 425/706 /home/rshah133/bcd/dataset/test/images/9b86016c01b2566e91962ed6bf78339d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 426/706 /home/rshah133/bcd/dataset/test/images/9b941fde3b9c95f6a9dd25d4755e9536.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 427/706 /home/rshah133/bcd/dataset/test/images/9ba92f29441854cfcb0c2abc08a013c6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 428/706 /home/rshah133/bcd/dataset/test/images/9bfaf5daec30606b515d2c005f29f0dc.jpg: 1024x1024 2 Masss, 3 Spiculations, 2.3ms\n",
      "image 429/706 /home/rshah133/bcd/dataset/test/images/9ca728553d6b22dbce7e5af4eb380424.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 430/706 /home/rshah133/bcd/dataset/test/images/9cd3302498c855aa589df212b12524da.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 431/706 /home/rshah133/bcd/dataset/test/images/9e25ba10f5cb25613d5181240272c1b5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 432/706 /home/rshah133/bcd/dataset/test/images/9ea9d05c4f2b57688f04257d9b9b6ab5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 433/706 /home/rshah133/bcd/dataset/test/images/9eac03525ce74859de0f3643d611ef78.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 434/706 /home/rshah133/bcd/dataset/test/images/9edf7793eb2d8981f2635dcb59f7568c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 435/706 /home/rshah133/bcd/dataset/test/images/9f026c6261ee776bea03ed2f4dea8f37.jpg: 1024x1024 2 Masss, 4 Spiculations, 2.3ms\n",
      "image 436/706 /home/rshah133/bcd/dataset/test/images/9f3a7288c7c0d992ffe69a23fe34b1e4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 437/706 /home/rshah133/bcd/dataset/test/images/9f63e7d767a3361df11d8aaec234aaef.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 438/706 /home/rshah133/bcd/dataset/test/images/9f65a2368a5df60f1910d687067ced3b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 439/706 /home/rshah133/bcd/dataset/test/images/9faf94bbaf5fa58149b5aee0d0f97c0f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 440/706 /home/rshah133/bcd/dataset/test/images/9faf9e04c92982aee3556e2db6737898.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 441/706 /home/rshah133/bcd/dataset/test/images/9fb8a3f50f6864433a9e5c2ce2ab3e11.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 442/706 /home/rshah133/bcd/dataset/test/images/9ff6c2a3ec1f88171fc05749f7c174ec.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 443/706 /home/rshah133/bcd/dataset/test/images/a02b0030f2550a19502987663d712ec7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 444/706 /home/rshah133/bcd/dataset/test/images/a0360303198e7a4b60566c2d2193e7b8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 445/706 /home/rshah133/bcd/dataset/test/images/a0694adf9540b4f755dfdbcf3b1eb725.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 446/706 /home/rshah133/bcd/dataset/test/images/a08fcff268ed16f6008b179b4d7368fe.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 447/706 /home/rshah133/bcd/dataset/test/images/a0cdb392b0d791725f8aea7f3f7f2c22.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 448/706 /home/rshah133/bcd/dataset/test/images/a0d04a7372a60d2a83c06d731a619c16.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 449/706 /home/rshah133/bcd/dataset/test/images/a0d839825d6307104467c0f2a11c6ed0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 450/706 /home/rshah133/bcd/dataset/test/images/a0d8764fd9aab586c329e0458f120ee5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 451/706 /home/rshah133/bcd/dataset/test/images/a0e6576e376ac1c8a484e2f15daabb87.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 452/706 /home/rshah133/bcd/dataset/test/images/a0fdff91676e8e3cee89af8a2d0eea82.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 453/706 /home/rshah133/bcd/dataset/test/images/a110a8dfc5cd1826cac846b0b30e6f8b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 454/706 /home/rshah133/bcd/dataset/test/images/a129ca2e83de818bb229abd42e8533b2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 455/706 /home/rshah133/bcd/dataset/test/images/a140bbecbcf3861c90e0db5440c420b0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 456/706 /home/rshah133/bcd/dataset/test/images/a164ae0daebd0d84305d29c1c0746ff4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 457/706 /home/rshah133/bcd/dataset/test/images/a199ec9c4484f322545edda0e5b56316.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 458/706 /home/rshah133/bcd/dataset/test/images/a1e6ff1084b1af114814a95a83f5e744.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 459/706 /home/rshah133/bcd/dataset/test/images/a251204836e86f9eca510afa7a79d450.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 460/706 /home/rshah133/bcd/dataset/test/images/a2ce545b7d7d400e6599dcba1fb0b5b6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 461/706 /home/rshah133/bcd/dataset/test/images/a2d73fa3622b7227587f480a63d24ab0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 462/706 /home/rshah133/bcd/dataset/test/images/a3214c506a005b639b4d720de9cea847.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 463/706 /home/rshah133/bcd/dataset/test/images/a321db55863a3c192f1b6ba790e62c07.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 464/706 /home/rshah133/bcd/dataset/test/images/a3415116030171359f15e0c14f9e75b1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 465/706 /home/rshah133/bcd/dataset/test/images/a37e508fc994c1c7a846ec23edfb400f.jpg: 1024x1024 1 Mass, 8 Spiculations, 2.3ms\n",
      "image 466/706 /home/rshah133/bcd/dataset/test/images/a42275264e5c92ac2f49e6a858f9a6ee.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 467/706 /home/rshah133/bcd/dataset/test/images/a4e1902203b851213146380f19a6891e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 468/706 /home/rshah133/bcd/dataset/test/images/a4eed594bef1cd59ed0b567f7a1cd7f6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 469/706 /home/rshah133/bcd/dataset/test/images/a5679dc25691dc85f0639be26b421195.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 470/706 /home/rshah133/bcd/dataset/test/images/a629996b0281b6590c706924e3a4e731.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 471/706 /home/rshah133/bcd/dataset/test/images/a68ac084d4c324ce9376320a34362558.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 472/706 /home/rshah133/bcd/dataset/test/images/a6bb433105ba47d9cdc9f368a8c261a9.jpg: 1024x1024 2 Masss, 2 Spiculations, 2.3ms\n",
      "image 473/706 /home/rshah133/bcd/dataset/test/images/a6f2c04678dba416587a08a4a68558f4.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 474/706 /home/rshah133/bcd/dataset/test/images/a7215359f4ab5efc6d81f57543d0a8bd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 475/706 /home/rshah133/bcd/dataset/test/images/a726e03b371093bf18cf884c39dad799.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 476/706 /home/rshah133/bcd/dataset/test/images/a743c234e305205215516a957dc669cf.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 477/706 /home/rshah133/bcd/dataset/test/images/a763d5dfd875b5575918bd8e97c651f6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 478/706 /home/rshah133/bcd/dataset/test/images/a7cc2e20f89f7797f89c787a5a6e0e58.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 479/706 /home/rshah133/bcd/dataset/test/images/a7d6038b8b078c125efb641d7e1e4ba1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 480/706 /home/rshah133/bcd/dataset/test/images/a7de2c103d8abf7da6963cf18820ed81.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 481/706 /home/rshah133/bcd/dataset/test/images/a8472717fea3274901241416ac02349e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 482/706 /home/rshah133/bcd/dataset/test/images/a869427ece4cb34d43825be65705929b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 483/706 /home/rshah133/bcd/dataset/test/images/a89afd636c07ebb8d327d495ee3209db.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 484/706 /home/rshah133/bcd/dataset/test/images/a8ee04f2197f0ccc1eb61c3e3a8602a5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 485/706 /home/rshah133/bcd/dataset/test/images/a8f4c712717ecf44064c37cc841154f1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 486/706 /home/rshah133/bcd/dataset/test/images/a91da35c2c5f5b726321511b4157ce36.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 487/706 /home/rshah133/bcd/dataset/test/images/a967d061ad8acb167fbc7cb07f3f289b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 488/706 /home/rshah133/bcd/dataset/test/images/a983c256635655ed394ed6805abf0499.jpg: 1024x1024 1 Mass, 6 Spiculations, 2.3ms\n",
      "image 489/706 /home/rshah133/bcd/dataset/test/images/a990c441ca083bb48de1d0d61709e80e.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 490/706 /home/rshah133/bcd/dataset/test/images/a9affff93a9e6059f5dc3c02be3ce280.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 491/706 /home/rshah133/bcd/dataset/test/images/a9bfa788e807e641ee576e4f040749e7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 492/706 /home/rshah133/bcd/dataset/test/images/a9f3f9e0195685ef7e02ecb2f90df158.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 493/706 /home/rshah133/bcd/dataset/test/images/aa02e8c5422114d20da11c573d0ee8ee.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 494/706 /home/rshah133/bcd/dataset/test/images/aa5a2d0995c8ade68690438531dfd770.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 495/706 /home/rshah133/bcd/dataset/test/images/ac315834dc489efe6d1e96d93ae8369d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 496/706 /home/rshah133/bcd/dataset/test/images/acbc0758f9ace5d7e07540e3c207bccc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 497/706 /home/rshah133/bcd/dataset/test/images/ad1006a223318d07bbc3e58443a621a0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 498/706 /home/rshah133/bcd/dataset/test/images/ad1966572be8828018237cd3ff44ae65.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 499/706 /home/rshah133/bcd/dataset/test/images/adf961b5379855af0293ca526f3d0c51.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 500/706 /home/rshah133/bcd/dataset/test/images/ae672f355541acfae894998dea1ec998.jpg: 1024x1024 2 Masss, 5 Spiculations, 2.3ms\n",
      "image 501/706 /home/rshah133/bcd/dataset/test/images/aef8595fed1885ce9cb1644ba5d88f6f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 502/706 /home/rshah133/bcd/dataset/test/images/af5c3f9e3b64ead393c4b160eb3349f8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 503/706 /home/rshah133/bcd/dataset/test/images/af713d9daaedd08d399db54b08f0fa14.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 504/706 /home/rshah133/bcd/dataset/test/images/af72a8d27de519be26f82dc872eb4de0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 505/706 /home/rshah133/bcd/dataset/test/images/afd2aeb98826aa8c3ae237b856e7097b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 506/706 /home/rshah133/bcd/dataset/test/images/b021bb379f747c45e88e5285b97f0ab1.jpg: 1024x1024 1 Mass, 2 Spiculations, 2.3ms\n",
      "image 507/706 /home/rshah133/bcd/dataset/test/images/b0251c254808b8d6de51d69952fb35d0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 508/706 /home/rshah133/bcd/dataset/test/images/b060b8505d05d3c732ac021624e07572.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 509/706 /home/rshah133/bcd/dataset/test/images/b163d5081f17dcf491d3364762732154.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 510/706 /home/rshah133/bcd/dataset/test/images/b170cb834c8bccc382bc8a1b667e6100.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 511/706 /home/rshah133/bcd/dataset/test/images/b265dd3363160ba9ee2dd78759f7f03d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 512/706 /home/rshah133/bcd/dataset/test/images/b26f40af33a396c9bbb1a6eb6e3ac2fd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 513/706 /home/rshah133/bcd/dataset/test/images/b3314a4376544671be4d6247e4eab34f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 514/706 /home/rshah133/bcd/dataset/test/images/b36dc28c1d4668a643a7d5edc1ccbc5d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 515/706 /home/rshah133/bcd/dataset/test/images/b38c4d76e10c004a7b779c01b3f66da0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 516/706 /home/rshah133/bcd/dataset/test/images/b3e9bcccb175193705f4f94f06c0a9bb.jpg: 1024x1024 2 Masss, 4 Spiculations, 2.3ms\n",
      "image 517/706 /home/rshah133/bcd/dataset/test/images/b3faf86a872751ca591a20a46c68b7dc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 518/706 /home/rshah133/bcd/dataset/test/images/b4b83d6c6e16b93b623b9ac0943a665c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 519/706 /home/rshah133/bcd/dataset/test/images/b50b5943e02004c10ac6de73d93cbe50.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 520/706 /home/rshah133/bcd/dataset/test/images/b57c03d571a79a037a6e63194ae923ff.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 521/706 /home/rshah133/bcd/dataset/test/images/b5ae06a11207fe5bd03c4ff05dca25f9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 522/706 /home/rshah133/bcd/dataset/test/images/b5b3c0e3fc91e759bd354a9601855ec3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 523/706 /home/rshah133/bcd/dataset/test/images/b5b4758224e6a66a587182fcdc5f1f1d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 524/706 /home/rshah133/bcd/dataset/test/images/b5dd38ab5b600ce41e1afafe67f56b3c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 525/706 /home/rshah133/bcd/dataset/test/images/b68769ba266c8a6ccfc95b649e14e23c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 526/706 /home/rshah133/bcd/dataset/test/images/b6c0b132664a9efded1830d35fad1772.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 527/706 /home/rshah133/bcd/dataset/test/images/b6f1e05b3f5da14ffa7df86d7586cc17.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 528/706 /home/rshah133/bcd/dataset/test/images/b72971acec10b39f4582a1f908224dba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 529/706 /home/rshah133/bcd/dataset/test/images/b74f95f32636aff0b94540891c6b1f14.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 530/706 /home/rshah133/bcd/dataset/test/images/b75d6c0a7d9ca2545b994559f1327422.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 531/706 /home/rshah133/bcd/dataset/test/images/b7aab83cdd9f122ad864ef9a1a8f6979.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 532/706 /home/rshah133/bcd/dataset/test/images/b7e56b7480ec9c0243f0d552c416288b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 533/706 /home/rshah133/bcd/dataset/test/images/b7fc54391dddda25d09ba4427e394ce7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 534/706 /home/rshah133/bcd/dataset/test/images/b80aec227daf048bc723532de2fadecc.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 535/706 /home/rshah133/bcd/dataset/test/images/b821f26947d67932afed6e9bf64d23e1.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 536/706 /home/rshah133/bcd/dataset/test/images/b83a2bb098dbb6c6de8bf68d45604d0f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 537/706 /home/rshah133/bcd/dataset/test/images/b841c1e419eaa15e8510dbc178dd0e21.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 538/706 /home/rshah133/bcd/dataset/test/images/b84c938e5d6e25da98625dbba840b521.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 539/706 /home/rshah133/bcd/dataset/test/images/b8a5dccad0d098308ff3296000716b52.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 540/706 /home/rshah133/bcd/dataset/test/images/b8ad72c3472c5490c59f664b2a6f6269.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 541/706 /home/rshah133/bcd/dataset/test/images/b90a0d1dcb980a1d0dd62562ae015305.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 542/706 /home/rshah133/bcd/dataset/test/images/b934cdb31aeabf5d6cbeb6caa32ab73b.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 543/706 /home/rshah133/bcd/dataset/test/images/b95641a993217e0ad74fe10d2304c3d9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 544/706 /home/rshah133/bcd/dataset/test/images/baf7c94a68bf95aea8bc26e1903c0ebe.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 545/706 /home/rshah133/bcd/dataset/test/images/bb0b2baa47fd2d18a435cbaccdcf4fdd.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 546/706 /home/rshah133/bcd/dataset/test/images/bb129d0a7332984110613e5e7d4ce719.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 547/706 /home/rshah133/bcd/dataset/test/images/bb99ba8cd1313281b5e78c662e07e012.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 548/706 /home/rshah133/bcd/dataset/test/images/bc58e54ec75acfc3acfb248f409ff2f4.jpg: 1024x1024 1 Spiculation, 2.3ms\n",
      "image 549/706 /home/rshah133/bcd/dataset/test/images/bccead060b49d9a6034fb98165cf925c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 550/706 /home/rshah133/bcd/dataset/test/images/bcd4f8ae5e07d0bdda74eaf649898a4c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 551/706 /home/rshah133/bcd/dataset/test/images/bce1addbe037d058ce2bb263acbf77ac.jpg: 1024x1024 3 Masss, 11 Spiculations, 2.3ms\n",
      "image 552/706 /home/rshah133/bcd/dataset/test/images/bd8c59601a3dfcde6c31d32aef7e8c93.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 553/706 /home/rshah133/bcd/dataset/test/images/bdaf3b28d1255fed45df39f64fc78aba.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 554/706 /home/rshah133/bcd/dataset/test/images/bdd807672f4efedab5c5cb3f0e65e7b5.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 555/706 /home/rshah133/bcd/dataset/test/images/bdf1539e07e60cfcb5e7833f5b63fa86.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 556/706 /home/rshah133/bcd/dataset/test/images/bed07d0a971ee8225e982dcfc16e58e4.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 557/706 /home/rshah133/bcd/dataset/test/images/bf20f3ea483e8f4baf95e150f52dece1.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 558/706 /home/rshah133/bcd/dataset/test/images/bf62934c9cb946d05b37ca6fa31c3651.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 559/706 /home/rshah133/bcd/dataset/test/images/bf7c12f171dff15c6a206408e42e89ac.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 560/706 /home/rshah133/bcd/dataset/test/images/bfd31e5e6ba3c8df271e317b0d87576f.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 561/706 /home/rshah133/bcd/dataset/test/images/bfd774c3fea3b7a9bae2d1bfba1cf5a7.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 562/706 /home/rshah133/bcd/dataset/test/images/c07913233d9119af17fb07e09717aa30.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 563/706 /home/rshah133/bcd/dataset/test/images/c07b5d9d6e2d0449dde2b34a432fc3b3.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 564/706 /home/rshah133/bcd/dataset/test/images/c09132c25d096cb951dd2d99f29c8230.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 565/706 /home/rshah133/bcd/dataset/test/images/c09db8206b7399d68e2e5a3e599fd237.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 566/706 /home/rshah133/bcd/dataset/test/images/c109ce18d872c340378acdfa12d4a058.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 567/706 /home/rshah133/bcd/dataset/test/images/c171fed7a869e9cb41c9a10e7ee6f4f9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 568/706 /home/rshah133/bcd/dataset/test/images/c1bbd7498883deb078c151ee8ef2e3e2.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 569/706 /home/rshah133/bcd/dataset/test/images/c1edef455c1d305e6674fcf0d9c3c195.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 570/706 /home/rshah133/bcd/dataset/test/images/c23e79de744ae741ec38e1f8db631798.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 571/706 /home/rshah133/bcd/dataset/test/images/c2a17760669a893b3e28ac5eac266cf7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 572/706 /home/rshah133/bcd/dataset/test/images/c368ddd11e70a207a8b86f543eb0b5cf.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 573/706 /home/rshah133/bcd/dataset/test/images/c58233033d21865c0c1e8f9b353d60ba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 574/706 /home/rshah133/bcd/dataset/test/images/c66ed5980ba90c803b928174c5623327.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 575/706 /home/rshah133/bcd/dataset/test/images/c6748f2e0790cca1d48a24a989c6e1c6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 576/706 /home/rshah133/bcd/dataset/test/images/c688d8438a1d18b36bc8813f900ebeb0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 577/706 /home/rshah133/bcd/dataset/test/images/c8673267271111cc481f2793d94eb565.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 578/706 /home/rshah133/bcd/dataset/test/images/c8d0f2ace6a0b244914bfeccaa0d50ff.jpg: 1024x1024 3 Masss, 17 Spiculations, 2.3ms\n",
      "image 579/706 /home/rshah133/bcd/dataset/test/images/c8fc55b240f0f3dd7c075b367160f289.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 580/706 /home/rshah133/bcd/dataset/test/images/c948f95852574751c684120ab64a5af7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 581/706 /home/rshah133/bcd/dataset/test/images/c99575f6b786336b2c51991f2e84ec91.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 582/706 /home/rshah133/bcd/dataset/test/images/ca0d26213dee21e7f9293cf24c5fd8e1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 583/706 /home/rshah133/bcd/dataset/test/images/cb02caed6492a9619e93a3bd265a9c7f.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 584/706 /home/rshah133/bcd/dataset/test/images/cc36988b2a3ff37cdda4b84b92f0924c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 585/706 /home/rshah133/bcd/dataset/test/images/ce4cbd6f019b513850603189efd8431c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 586/706 /home/rshah133/bcd/dataset/test/images/cef78bc38a146cacf45b3538abc4b7e1.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 587/706 /home/rshah133/bcd/dataset/test/images/cfdda9d0be846ba0716fcf18ae3abf70.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 588/706 /home/rshah133/bcd/dataset/test/images/d028ffee146b31e84cb8cce392beafe7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 589/706 /home/rshah133/bcd/dataset/test/images/d02f7fcc6f0b63b2e5f548c5d595aaba.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 590/706 /home/rshah133/bcd/dataset/test/images/d035c81f7e81c0a845b61e566bf7a4bb.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 591/706 /home/rshah133/bcd/dataset/test/images/d064c9312f907d3f72692915156f3db8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 592/706 /home/rshah133/bcd/dataset/test/images/d25ea7dce5e60b1e054044acb722096c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 593/706 /home/rshah133/bcd/dataset/test/images/d3608e08c17fa916dcde1203ed5faf61.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 594/706 /home/rshah133/bcd/dataset/test/images/d3aced0c7e8fe9c1bd498eeb72cb6048.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 595/706 /home/rshah133/bcd/dataset/test/images/d42ebe160ea29f5fc30b0569f3e9c734.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 596/706 /home/rshah133/bcd/dataset/test/images/d43f6852f99857f4efcd0c67cdbd66ae.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 597/706 /home/rshah133/bcd/dataset/test/images/d4f53fa0caf2d34395916ab3e1630cd9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 598/706 /home/rshah133/bcd/dataset/test/images/d5701f000de83388af9171cea1427a7e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 599/706 /home/rshah133/bcd/dataset/test/images/d590f7d1cd57ab842a5bef5241cac7b7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 600/706 /home/rshah133/bcd/dataset/test/images/d5fbbd30a1d4a089716622b4303b1b58.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 601/706 /home/rshah133/bcd/dataset/test/images/d75092349d2b99d2cc62f5f5a61cd164.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 602/706 /home/rshah133/bcd/dataset/test/images/d7815929d503a461d7f7e25a7a18bd86.jpg: 1024x1024 3 Masss, 7 Spiculations, 2.3ms\n",
      "image 603/706 /home/rshah133/bcd/dataset/test/images/d7b13c6b2c47e38281ad5148a0d7355e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 604/706 /home/rshah133/bcd/dataset/test/images/d7e4f2a7ee93c5fc4d5b79989ce45210.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 605/706 /home/rshah133/bcd/dataset/test/images/d838dc1fa3b1c99fad6af99fef9f2b77.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 606/706 /home/rshah133/bcd/dataset/test/images/d83b16559c3ad828bd86db23e4f11243.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 607/706 /home/rshah133/bcd/dataset/test/images/d91825b15e444b4cab3a50b8927a7b6a.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 608/706 /home/rshah133/bcd/dataset/test/images/d9608f84e139686b90911402c509fc1e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 609/706 /home/rshah133/bcd/dataset/test/images/da165bf60a8e8739a597d51b47eed60c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 610/706 /home/rshah133/bcd/dataset/test/images/dab9cb0c72531563a2d5f819cd147717.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 611/706 /home/rshah133/bcd/dataset/test/images/db72a9a3c5827c1982b9b6d953c3dc04.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 612/706 /home/rshah133/bcd/dataset/test/images/db995adee9848eeb14830fbc984d7457.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 613/706 /home/rshah133/bcd/dataset/test/images/dcedab9fff926c42215b3da835e9c9f8.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 614/706 /home/rshah133/bcd/dataset/test/images/ddf0592485d93d7084c29f1fa5e5c443.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 615/706 /home/rshah133/bcd/dataset/test/images/de0938995163311b26eaee4155b8d111.jpg: 1024x1024 4 Masss, 8 Spiculations, 2.3ms\n",
      "image 616/706 /home/rshah133/bcd/dataset/test/images/de3db479c679661e4e3c686ec1e0ced4.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 617/706 /home/rshah133/bcd/dataset/test/images/de70e46e59e9c810a19f2409dc547802.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 618/706 /home/rshah133/bcd/dataset/test/images/dec4540f406b4e556983b4f76504ee30.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 619/706 /home/rshah133/bcd/dataset/test/images/ded6d333fe65171adf1e6047dd29a7b8.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 620/706 /home/rshah133/bcd/dataset/test/images/df1a94aad76bd2e7beadcf00dfc715bb.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 621/706 /home/rshah133/bcd/dataset/test/images/df23dd36fa532db5c49f27bbac7e6eaa.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 622/706 /home/rshah133/bcd/dataset/test/images/df4b1cfb384dab76abc34cc4db0f5b30.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 623/706 /home/rshah133/bcd/dataset/test/images/df8b9763dad465e61b23875932af4f7d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 624/706 /home/rshah133/bcd/dataset/test/images/e0f23bcf8a746448d3357d77218431e9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 625/706 /home/rshah133/bcd/dataset/test/images/e13b73b4a3a11c6ddc2246bc62af9529.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 626/706 /home/rshah133/bcd/dataset/test/images/e14aa863caca3f418a89edbc4d2cec42.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 627/706 /home/rshah133/bcd/dataset/test/images/e160aa97a7ea45e3ac38ecc0585baea6.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 628/706 /home/rshah133/bcd/dataset/test/images/e1ec4b67b6d6308177986ec74b412824.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 629/706 /home/rshah133/bcd/dataset/test/images/e22e24c243bde531bd5ed18e90702768.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 630/706 /home/rshah133/bcd/dataset/test/images/e2a9f68e5f57465acea8f2f585e5634e.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 631/706 /home/rshah133/bcd/dataset/test/images/e2aac118bc937b21a9be2c705b6cbab9.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 632/706 /home/rshah133/bcd/dataset/test/images/e2dfa8e5c2b50091ffbdb20dff13cd01.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 633/706 /home/rshah133/bcd/dataset/test/images/e2e3e576991129315bfe76683798a270.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 634/706 /home/rshah133/bcd/dataset/test/images/e4dd9edf701bdb5d7c835bae4d7fe62a.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 635/706 /home/rshah133/bcd/dataset/test/images/e507bee7c9fba777c89f4f1a96887f78.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 636/706 /home/rshah133/bcd/dataset/test/images/e542f9387674418e51d71d44dd35a496.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 637/706 /home/rshah133/bcd/dataset/test/images/e579d7a7361e460066d86a92b169606d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 638/706 /home/rshah133/bcd/dataset/test/images/e584baaff798425b74b2f255c6eaf02e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 639/706 /home/rshah133/bcd/dataset/test/images/e5bc3f728fad5d69a6be168c04e6855b.jpg: 1024x1024 2 Masss, 2.3ms\n",
      "image 640/706 /home/rshah133/bcd/dataset/test/images/e608d957bf2ecd894c524d0969b05868.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 641/706 /home/rshah133/bcd/dataset/test/images/e6147b88edd1b0dca1772e8e47e3ed82.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 642/706 /home/rshah133/bcd/dataset/test/images/e648eee49dff6f5a92bccdae2b8a48d0.jpg: 1024x1024 2 Masss, 4 Spiculations, 2.3ms\n",
      "image 643/706 /home/rshah133/bcd/dataset/test/images/e6d1fee02d8d4700ae9923cc5ffe25f3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 644/706 /home/rshah133/bcd/dataset/test/images/e755c240ce3e6567fdfec4fca1544547.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 645/706 /home/rshah133/bcd/dataset/test/images/e79f419d756e9902fc6ff80ca0d7f7a3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 646/706 /home/rshah133/bcd/dataset/test/images/e7c534f3c4d99a2a017cd64191b73923.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 647/706 /home/rshah133/bcd/dataset/test/images/e80bb54bc1220a5b522767f5bc2be268.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 648/706 /home/rshah133/bcd/dataset/test/images/e8622a694ac7d18bb14ae8dde1346294.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 649/706 /home/rshah133/bcd/dataset/test/images/e8b40315a5d5ca3d4d50cf215474b056.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 650/706 /home/rshah133/bcd/dataset/test/images/e9136e59d32433a6803d72c8c97fe513.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 651/706 /home/rshah133/bcd/dataset/test/images/e97550e9877faea678557c5e3d52438b.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 652/706 /home/rshah133/bcd/dataset/test/images/e9a772495692cf0d9ca09e8f5eea3453.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 653/706 /home/rshah133/bcd/dataset/test/images/e9c639f5926584509413a6d71f7be603.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 654/706 /home/rshah133/bcd/dataset/test/images/ebdd44111a12abdfb8846e43788c16a1.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 655/706 /home/rshah133/bcd/dataset/test/images/ebdf18c659f2323b6c1efd9396916830.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 656/706 /home/rshah133/bcd/dataset/test/images/ed15e2630a1d858c0e0fa9aa2348eceb.jpg: 1024x1024 2 Masss, 6 Spiculations, 2.4ms\n",
      "image 657/706 /home/rshah133/bcd/dataset/test/images/eefd7f23922a576ee1fafc96e5815ecd.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 658/706 /home/rshah133/bcd/dataset/test/images/ef019107c41e1e1bf76d8e5dd1262bd5.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 659/706 /home/rshah133/bcd/dataset/test/images/efcb0eafdd9b5125468295d63e6ce173.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 660/706 /home/rshah133/bcd/dataset/test/images/f019726318cc1f7ab98ae646583d8895.jpg: 1024x1024 (no detections), 2.4ms\n",
      "image 661/706 /home/rshah133/bcd/dataset/test/images/f080cbb94257cf0e7549898060822902.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 662/706 /home/rshah133/bcd/dataset/test/images/f1097a8a50765e2261af176d00347cf0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 663/706 /home/rshah133/bcd/dataset/test/images/f1b0fbd4eebff392ed4b9886034c29ca.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 664/706 /home/rshah133/bcd/dataset/test/images/f1bfdcca5002d093e4b07e0099e252ec.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 665/706 /home/rshah133/bcd/dataset/test/images/f1dd8037a1a5f684cebc10a22e2e2797.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 666/706 /home/rshah133/bcd/dataset/test/images/f27721b219f110a419193176e5e53151.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 667/706 /home/rshah133/bcd/dataset/test/images/f2ebfa37e63f0aa3306b4cfdd4c7a18c.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 668/706 /home/rshah133/bcd/dataset/test/images/f3b7da5f9ca3b14e89f6a66b7d1c2ef0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 669/706 /home/rshah133/bcd/dataset/test/images/f3cbed97f4bb7897467e1e8bab45966e.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 670/706 /home/rshah133/bcd/dataset/test/images/f3f7753468997b03b3d8707edd9bef37.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 671/706 /home/rshah133/bcd/dataset/test/images/f4148e1f2c31d89196e03761e4c23315.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 672/706 /home/rshah133/bcd/dataset/test/images/f440c8794f743a8652cf8b76cc666f72.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 673/706 /home/rshah133/bcd/dataset/test/images/f51e0c5db5201a2cf58b424437007197.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 674/706 /home/rshah133/bcd/dataset/test/images/f5423eafd23bac6bf7452214fe3c5c07.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 675/706 /home/rshah133/bcd/dataset/test/images/f554eb48ce46c7e5035e731257e35d91.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 676/706 /home/rshah133/bcd/dataset/test/images/f5b9c502a087f77d0606b0291a2e0606.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 677/706 /home/rshah133/bcd/dataset/test/images/f5f07a92f7baa4da052ee9cf08369e63.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 678/706 /home/rshah133/bcd/dataset/test/images/f6b19e19ebc1302afc17c9a3140a4ae9.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 679/706 /home/rshah133/bcd/dataset/test/images/f6c7f3c3e03d612002800f20b1282309.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 680/706 /home/rshah133/bcd/dataset/test/images/f71ca674d3bf9549f9e68b67ead86d25.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 681/706 /home/rshah133/bcd/dataset/test/images/f75e7aff7268ba2e462c284e30cfc5b5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 682/706 /home/rshah133/bcd/dataset/test/images/f78853b3aa2445fb60d677f6f5d82ca7.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 683/706 /home/rshah133/bcd/dataset/test/images/f792b9d57722dd5d5ac34e3772e6afbc.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 684/706 /home/rshah133/bcd/dataset/test/images/f7b6c452218153d612c4c28f14971296.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 685/706 /home/rshah133/bcd/dataset/test/images/f7cdf7b22955e66d34cc1efccdab5fbf.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 686/706 /home/rshah133/bcd/dataset/test/images/f7d9acd8e1f576d801c24f90ad5a99d3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 687/706 /home/rshah133/bcd/dataset/test/images/f824ca07593cb971f4d2348de8def504.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 688/706 /home/rshah133/bcd/dataset/test/images/f97cd5b8d0049cbceda56350c01a66d5.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 689/706 /home/rshah133/bcd/dataset/test/images/f9918b3feb92e1f38a0c86a6a28c14a0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 690/706 /home/rshah133/bcd/dataset/test/images/fa0104443e2e60effcb1e0222a9b015d.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 691/706 /home/rshah133/bcd/dataset/test/images/fa145776ca39abb6df42fc67e519bcf3.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 692/706 /home/rshah133/bcd/dataset/test/images/fa2f7816bf1b07f2104aa4edeff9b107.jpg: 1024x1024 1 Mass, 2.3ms\n",
      "image 693/706 /home/rshah133/bcd/dataset/test/images/fa62bfb18ecd5fe37a4cc21b957a4eed.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 694/706 /home/rshah133/bcd/dataset/test/images/fabc21b31c91a6f8b0900a6767d46515.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 695/706 /home/rshah133/bcd/dataset/test/images/fae5f8cf37f37b672454a67ff7b16ef0.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 696/706 /home/rshah133/bcd/dataset/test/images/fae8ad37fe9584d2f8e8009abc0ee8a6.jpg: 1024x1024 (no detections), 2.3ms\n",
      "image 697/706 /home/rshah133/bcd/dataset/test/images/fb37f7f1423480f1173ff376ca8e6ada.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 698/706 /home/rshah133/bcd/dataset/test/images/fb413cf6ef972090326d9886fa500aa2.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 699/706 /home/rshah133/bcd/dataset/test/images/fc35547785ce94420408f99bbfad57fb.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 700/706 /home/rshah133/bcd/dataset/test/images/fd0c0b70adb9608b5b2dcf57f05668f3.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 701/706 /home/rshah133/bcd/dataset/test/images/fd5b39474bd0c0e81bf3af47bbc0c487.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 702/706 /home/rshah133/bcd/dataset/test/images/fde50065b6d598d0bb62a08a0f0d97b7.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 703/706 /home/rshah133/bcd/dataset/test/images/fe4273ea38a3028f91f80e5e12a84301.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 704/706 /home/rshah133/bcd/dataset/test/images/ff476c753265aa0baa6685c58d5ef05a.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 705/706 /home/rshah133/bcd/dataset/test/images/ff6716b4004598670fa72d8cefea454c.jpg: 1024x1024 (no detections), 3.3ms\n",
      "image 706/706 /home/rshah133/bcd/dataset/test/images/ffd951bc4cd3d91f8994d2d1d36f038d.jpg: 1024x1024 (no detections), 3.3ms\n",
      "Speed: 6.9ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (12, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "54 labels saved to runs/detect/predict/labels\n"
     ]
    }
   ],
   "source": [
    "progress_file = 'prediction_progress.json'\n",
    "\n",
    "def save_progress(current_index):\n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump({'last_processed': current_index}, f)\n",
    "\n",
    "def load_progress():\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            return json.load(f)['last_processed']\n",
    "    return 0\n",
    "\n",
    "# Loading the best model\n",
    "best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "\n",
    "test_img_path = data_loaded['val']\n",
    "\n",
    "start_index = load_progress()\n",
    "\n",
    "chunk_size = 48  # Adjust based on your available memory\n",
    "for i in range(start_index, len(test_img_path), chunk_size):\n",
    "    chunk_end = min(i + chunk_size, len(test_img_path))\n",
    "    current_chunk = test_img_path[i:chunk_end]\n",
    "    \n",
    "    try:\n",
    "        results = best_model.predict(source = current_chunk, save = True, save_txt = True, conf = 0.10, batch = chunk_size//4, stream = True)\n",
    "        \n",
    "        # code for post - processing results for later\n",
    "        for r in results:\n",
    "            pass  \n",
    "            \n",
    "        save_progress(chunk_end)\n",
    "        \n",
    "    except Exception as e:\n",
    "        save_progress(i)\n",
    "        print(f\"Prediction stopped at image {i}. Progress saved.\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92095830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "# test_img_path = data_loaded['val']\n",
    "# results = best_model.predict(source = test_img_path, save = True,  save_txt = True,  conf = 0.10, batch = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150e326",
   "metadata": {},
   "source": [
    "Run this cell as it is and take screenshot of the output. This code is for calculating the metrics for test data\n",
    "\n",
    "u can play with conf keep between 0.05-0.2 (for our use case). lower value means it predicts more but with less accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ea33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.68 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81156MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/rshah133/bcd/dataset/test/labels... 706 images, 72 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 706/706 [00:00<00:00, 1645.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/rshah133/bcd/dataset/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        706       2476      0.073    0.00961       0.04     0.0176\n",
      "                  Mass        412        459      0.471     0.0719      0.261      0.125\n",
      "           Spiculation        538       1627      0.331     0.0338      0.179     0.0683\n",
      "Suspicious Calcification        149        192          0          0          0          0\n",
      "Architectural Distortion         29         29          0          0          0          0\n",
      "             Asymmetry         35         35          0          0          0          0\n",
      "       Focal Asymmetry         80         80          0          0          0          0\n",
      "       Skin Thickening         13         13          0          0          0          0\n",
      "      Global Asymmetry          7          7          0          0          0          0\n",
      " Suspicious Lymph Node         22         24          0          0          0          0\n",
      "       Skin Retraction          2          3          0          0          0          0\n",
      "     Nipple Retraction          7          7          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = best_model.val(data = test_path, conf = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1198cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs/detect/predict/labels'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prediction_dirs():\n",
    "    base_dir = \"runs/detect\"\n",
    "    \n",
    "    predict_dirs = [d for d in os.listdir(base_dir) if d.startswith('predict')]\n",
    "    predict_dirs.sort(key=lambda x: int(x.replace('predict', '')) if x != 'predict' else 0)\n",
    "    \n",
    "    return f\"{base_dir}/{predict_dirs[-1]}/labels\"\n",
    "\n",
    "predictions_dir = get_prediction_dirs()\n",
    "predictions_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7415e871-b0d0-4b1a-a837-651b772103ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving the predictions\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_images_dir = data_loaded['val']\n",
    "test_labels_dir = os.path.join(os.path.dirname(data_loaded['val']), 'labels')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_pred_dir, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO format labels\n",
    "def read_yolo_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "            confidence = float(parts[5]) if len(parts) > 5 else None\n",
    "            labels.append((int(class_id), x_center, y_center, width, height, confidence))\n",
    "    return labels\n",
    "\n",
    "# Function to draw bounding boxes on images\n",
    "def draw_boxes(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height, confidence = box\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        x_max = int((x_center + width / 2) * w)\n",
    "        y_max = int((y_center + height / 2) * h)\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color_dict[class_id], 2)\n",
    "    return image\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in os.listdir(test_images_dir):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Read ground truth labels\n",
    "        ground_truth_file = os.path.join(test_labels_dir, f\"{base_name}.txt\")\n",
    "        ground_truth_boxes = read_yolo_labels(ground_truth_file) if os.path.exists(ground_truth_file) else []\n",
    "\n",
    "        # Read prediction labels\n",
    "        prediction_file = os.path.join(predictions_dir, f\"{base_name}.txt\")\n",
    "        prediction_boxes = read_yolo_labels(prediction_file) if os.path.exists(prediction_file) else []\n",
    "\n",
    "        # Draw ground truth (green) and predictions (blue)\n",
    "        image_with_boxes_gt = draw_boxes(image.copy(), ground_truth_boxes)\n",
    "        image_with_boxes_pt = draw_boxes(image.copy(), prediction_boxes)\n",
    "\n",
    "        # Save annotated image\n",
    "        gt_output_path = os.path.join(output_labels_dir, image_file)\n",
    "        cv2.imwrite(gt_output_path, image_with_boxes_gt)\n",
    "\n",
    "        pt_output_path = os.path.join(output_pred_dir, image_file)\n",
    "        cv2.imwrite(pt_output_path, image_with_boxes_pt)\n",
    "\n",
    "print(\"Done saving the predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504c186",
   "metadata": {},
   "source": [
    "Code to combine images in a single pdf. This code take upto 20mins to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "pdf_file_path = \"combined_images.pdf\"\n",
    "\n",
    "\n",
    "with PdfPages(pdf_file_path) as pdf:\n",
    "    for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "        label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "        pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "        \n",
    "        img = cv2.resize(pred_img, (640, 640))\n",
    "        rgb_img = img.copy()\n",
    "        img = np.float32(img) / 255\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(16, 6))\n",
    "        axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[0].set_title('Ground Truth')\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[1].set_title('Prediction')\n",
    "        axs[1].axis('off')\n",
    "    \n",
    "print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e61d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1024x1024 (no detections), 942.6ms\n",
      "Speed: 7.0ms preprocess, 942.6ms inference, 45.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.0ms\n",
      "Speed: 5.0ms preprocess, 946.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 935.0ms\n",
      "Speed: 5.2ms preprocess, 935.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 914.1ms\n",
      "Speed: 5.0ms preprocess, 914.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 913.3ms\n",
      "Speed: 5.4ms preprocess, 913.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 942.4ms\n",
      "Speed: 5.1ms preprocess, 942.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 914.5ms\n",
      "Speed: 5.0ms preprocess, 914.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.4ms\n",
      "Speed: 7.9ms preprocess, 949.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 939.5ms\n",
      "Speed: 5.0ms preprocess, 939.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.9ms\n",
      "Speed: 6.9ms preprocess, 946.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.2ms\n",
      "Speed: 5.2ms preprocess, 943.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.8ms\n",
      "Speed: 5.1ms preprocess, 946.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.0ms\n",
      "Speed: 5.1ms preprocess, 950.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.1ms\n",
      "Speed: 5.1ms preprocess, 952.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.9ms\n",
      "Speed: 5.0ms preprocess, 943.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 911.8ms\n",
      "Speed: 5.1ms preprocess, 911.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.4ms\n",
      "Speed: 5.2ms preprocess, 948.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 936.9ms\n",
      "Speed: 5.2ms preprocess, 936.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 939.0ms\n",
      "Speed: 5.2ms preprocess, 939.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.9ms\n",
      "Speed: 5.0ms preprocess, 937.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 936.2ms\n",
      "Speed: 5.2ms preprocess, 936.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.6ms\n",
      "Speed: 5.1ms preprocess, 943.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 936.6ms\n",
      "Speed: 5.1ms preprocess, 936.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.7ms\n",
      "Speed: 5.3ms preprocess, 937.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 908.0ms\n",
      "Speed: 4.9ms preprocess, 908.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 917.3ms\n",
      "Speed: 5.9ms preprocess, 917.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 910.3ms\n",
      "Speed: 5.0ms preprocess, 910.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.7ms\n",
      "Speed: 5.1ms preprocess, 947.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 936.5ms\n",
      "Speed: 5.0ms preprocess, 936.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.8ms\n",
      "Speed: 5.1ms preprocess, 937.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.1ms\n",
      "Speed: 5.1ms preprocess, 948.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 907.6ms\n",
      "Speed: 5.0ms preprocess, 907.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.4ms\n",
      "Speed: 6.2ms preprocess, 949.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 923.8ms\n",
      "Speed: 5.2ms preprocess, 923.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 916.5ms\n",
      "Speed: 5.3ms preprocess, 916.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.4ms\n",
      "Speed: 5.2ms preprocess, 947.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.2ms\n",
      "Speed: 5.4ms preprocess, 941.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.1ms\n",
      "Speed: 5.1ms preprocess, 949.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 940.8ms\n",
      "Speed: 5.3ms preprocess, 940.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.4ms\n",
      "Speed: 5.1ms preprocess, 950.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 942.8ms\n",
      "Speed: 6.4ms preprocess, 942.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 928.1ms\n",
      "Speed: 5.2ms preprocess, 928.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 921.1ms\n",
      "Speed: 5.2ms preprocess, 921.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 911.6ms\n",
      "Speed: 5.3ms preprocess, 911.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.9ms\n",
      "Speed: 5.2ms preprocess, 952.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.0ms\n",
      "Speed: 5.2ms preprocess, 943.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.2ms\n",
      "Speed: 5.2ms preprocess, 943.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 913.9ms\n",
      "Speed: 5.1ms preprocess, 913.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 917.6ms\n",
      "Speed: 5.2ms preprocess, 917.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.4ms\n",
      "Speed: 6.5ms preprocess, 947.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 1 Mass, 942.1ms\n",
      "Speed: 5.1ms preprocess, 942.1ms inference, 68.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.1ms\n",
      "Speed: 5.3ms preprocess, 941.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.0ms\n",
      "Speed: 5.2ms preprocess, 941.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.8ms\n",
      "Speed: 7.4ms preprocess, 946.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.6ms\n",
      "Speed: 5.9ms preprocess, 943.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 921.4ms\n",
      "Speed: 5.1ms preprocess, 921.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 921.8ms\n",
      "Speed: 5.0ms preprocess, 921.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.3ms\n",
      "Speed: 5.0ms preprocess, 949.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 931.0ms\n",
      "Speed: 5.3ms preprocess, 931.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.8ms\n",
      "Speed: 5.1ms preprocess, 950.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.7ms\n",
      "Speed: 5.1ms preprocess, 950.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.1ms\n",
      "Speed: 5.3ms preprocess, 947.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.1ms\n",
      "Speed: 5.2ms preprocess, 946.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 942.5ms\n",
      "Speed: 5.2ms preprocess, 942.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.3ms\n",
      "Speed: 5.2ms preprocess, 953.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.0ms\n",
      "Speed: 5.2ms preprocess, 950.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.7ms\n",
      "Speed: 5.2ms preprocess, 943.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 967.4ms\n",
      "Speed: 6.3ms preprocess, 967.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.1ms\n",
      "Speed: 5.3ms preprocess, 950.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.2ms\n",
      "Speed: 5.1ms preprocess, 951.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 936.0ms\n",
      "Speed: 5.0ms preprocess, 936.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.9ms\n",
      "Speed: 5.1ms preprocess, 943.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.8ms\n",
      "Speed: 5.1ms preprocess, 937.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.5ms\n",
      "Speed: 5.6ms preprocess, 947.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.5ms\n",
      "Speed: 5.1ms preprocess, 945.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.4ms\n",
      "Speed: 5.0ms preprocess, 941.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 968.9ms\n",
      "Speed: 5.1ms preprocess, 968.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.7ms\n",
      "Speed: 5.1ms preprocess, 946.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.8ms\n",
      "Speed: 5.1ms preprocess, 953.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.0ms\n",
      "Speed: 5.2ms preprocess, 946.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.9ms\n",
      "Speed: 5.2ms preprocess, 950.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 916.9ms\n",
      "Speed: 5.1ms preprocess, 916.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.5ms\n",
      "Speed: 5.1ms preprocess, 951.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.0ms\n",
      "Speed: 5.1ms preprocess, 946.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.7ms\n",
      "Speed: 5.3ms preprocess, 952.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 940.9ms\n",
      "Speed: 6.9ms preprocess, 940.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 921.6ms\n",
      "Speed: 5.0ms preprocess, 921.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 910.9ms\n",
      "Speed: 5.3ms preprocess, 910.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 925.8ms\n",
      "Speed: 5.3ms preprocess, 925.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.4ms\n",
      "Speed: 5.2ms preprocess, 945.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.0ms\n",
      "Speed: 5.2ms preprocess, 949.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.5ms\n",
      "Speed: 5.4ms preprocess, 950.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.2ms\n",
      "Speed: 5.2ms preprocess, 956.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 959.2ms\n",
      "Speed: 5.1ms preprocess, 959.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 1 Mass, 2 Spiculations, 945.6ms\n",
      "Speed: 5.1ms preprocess, 945.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.3ms\n",
      "Speed: 7.5ms preprocess, 952.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.3ms\n",
      "Speed: 5.3ms preprocess, 949.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.1ms\n",
      "Speed: 5.2ms preprocess, 949.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.4ms\n",
      "Speed: 5.1ms preprocess, 955.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.0ms\n",
      "Speed: 5.1ms preprocess, 948.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.5ms\n",
      "Speed: 5.1ms preprocess, 946.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.3ms\n",
      "Speed: 5.2ms preprocess, 947.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.6ms\n",
      "Speed: 5.3ms preprocess, 952.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.7ms\n",
      "Speed: 5.1ms preprocess, 955.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 963.4ms\n",
      "Speed: 5.2ms preprocess, 963.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.2ms\n",
      "Speed: 5.1ms preprocess, 956.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.7ms\n",
      "Speed: 5.2ms preprocess, 950.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.3ms\n",
      "Speed: 5.3ms preprocess, 951.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.8ms\n",
      "Speed: 5.2ms preprocess, 945.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.6ms\n",
      "Speed: 5.3ms preprocess, 947.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.5ms\n",
      "Speed: 5.3ms preprocess, 947.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.1ms\n",
      "Speed: 5.1ms preprocess, 947.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.1ms\n",
      "Speed: 5.3ms preprocess, 951.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.0ms\n",
      "Speed: 5.2ms preprocess, 955.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 954.8ms\n",
      "Speed: 5.1ms preprocess, 954.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.4ms\n",
      "Speed: 5.0ms preprocess, 949.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.3ms\n",
      "Speed: 5.3ms preprocess, 953.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.8ms\n",
      "Speed: 6.2ms preprocess, 956.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.0ms\n",
      "Speed: 5.2ms preprocess, 950.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 962.8ms\n",
      "Speed: 5.0ms preprocess, 962.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.3ms\n",
      "Speed: 5.0ms preprocess, 953.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.0ms\n",
      "Speed: 5.4ms preprocess, 953.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 957.4ms\n",
      "Speed: 5.2ms preprocess, 957.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 964.3ms\n",
      "Speed: 5.3ms preprocess, 964.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.0ms\n",
      "Speed: 5.1ms preprocess, 952.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.7ms\n",
      "Speed: 5.5ms preprocess, 950.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.8ms\n",
      "Speed: 5.1ms preprocess, 953.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.8ms\n",
      "Speed: 5.1ms preprocess, 952.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.5ms\n",
      "Speed: 5.1ms preprocess, 952.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.5ms\n",
      "Speed: 5.3ms preprocess, 956.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.9ms\n",
      "Speed: 5.1ms preprocess, 951.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.5ms\n",
      "Speed: 6.2ms preprocess, 948.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 957.1ms\n",
      "Speed: 5.2ms preprocess, 957.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 961.4ms\n",
      "Speed: 5.2ms preprocess, 961.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 929.0ms\n",
      "Speed: 5.3ms preprocess, 929.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 926.5ms\n",
      "Speed: 5.2ms preprocess, 926.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.7ms\n",
      "Speed: 5.1ms preprocess, 953.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.9ms\n",
      "Speed: 5.2ms preprocess, 953.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.0ms\n",
      "Speed: 5.1ms preprocess, 946.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.1ms\n",
      "Speed: 8.0ms preprocess, 950.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 944.3ms\n",
      "Speed: 5.0ms preprocess, 944.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.0ms\n",
      "Speed: 5.3ms preprocess, 948.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.3ms\n",
      "Speed: 5.3ms preprocess, 950.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 944.9ms\n",
      "Speed: 5.1ms preprocess, 944.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.4ms\n",
      "Speed: 5.4ms preprocess, 948.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.5ms\n",
      "Speed: 5.1ms preprocess, 941.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.6ms\n",
      "Speed: 5.1ms preprocess, 943.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.0ms\n",
      "Speed: 5.0ms preprocess, 945.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.9ms\n",
      "Speed: 4.9ms preprocess, 937.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.9ms\n",
      "Speed: 5.1ms preprocess, 945.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 940.7ms\n",
      "Speed: 5.0ms preprocess, 940.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.1ms\n",
      "Speed: 5.0ms preprocess, 937.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 939.0ms\n",
      "Speed: 5.3ms preprocess, 939.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.4ms\n",
      "Speed: 5.1ms preprocess, 941.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.6ms\n",
      "Speed: 5.9ms preprocess, 945.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 923.8ms\n",
      "Speed: 5.0ms preprocess, 923.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.5ms\n",
      "Speed: 5.2ms preprocess, 950.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 922.8ms\n",
      "Speed: 5.0ms preprocess, 922.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 914.5ms\n",
      "Speed: 5.2ms preprocess, 914.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 944.6ms\n",
      "Speed: 5.1ms preprocess, 944.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.1ms\n",
      "Speed: 5.3ms preprocess, 946.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.9ms\n",
      "Speed: 5.1ms preprocess, 941.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.6ms\n",
      "Speed: 5.4ms preprocess, 937.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.7ms\n",
      "Speed: 5.2ms preprocess, 956.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.5ms\n",
      "Speed: 5.1ms preprocess, 950.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.6ms\n",
      "Speed: 5.1ms preprocess, 948.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 966.4ms\n",
      "Speed: 6.5ms preprocess, 966.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.5ms\n",
      "Speed: 5.1ms preprocess, 952.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 921.7ms\n",
      "Speed: 5.2ms preprocess, 921.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.1ms\n",
      "Speed: 5.3ms preprocess, 946.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.0ms\n",
      "Speed: 4.8ms preprocess, 949.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 965.1ms\n",
      "Speed: 5.1ms preprocess, 965.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 920.5ms\n",
      "Speed: 4.9ms preprocess, 920.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 954.4ms\n",
      "Speed: 6.3ms preprocess, 954.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.2ms\n",
      "Speed: 5.4ms preprocess, 951.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 944.5ms\n",
      "Speed: 5.3ms preprocess, 944.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 962.8ms\n",
      "Speed: 5.1ms preprocess, 962.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.0ms\n",
      "Speed: 5.4ms preprocess, 949.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.7ms\n",
      "Speed: 5.0ms preprocess, 949.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 986.1ms\n",
      "Speed: 5.2ms preprocess, 986.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 964.8ms\n",
      "Speed: 5.2ms preprocess, 964.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 957.0ms\n",
      "Speed: 5.2ms preprocess, 957.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 963.9ms\n",
      "Speed: 6.3ms preprocess, 963.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 976.1ms\n",
      "Speed: 5.4ms preprocess, 976.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 923.6ms\n",
      "Speed: 5.0ms preprocess, 923.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.4ms\n",
      "Speed: 5.4ms preprocess, 956.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 962.8ms\n",
      "Speed: 5.1ms preprocess, 962.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 971.6ms\n",
      "Speed: 5.2ms preprocess, 971.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 919.6ms\n",
      "Speed: 5.1ms preprocess, 919.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 943.1ms\n",
      "Speed: 5.2ms preprocess, 943.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.4ms\n",
      "Speed: 5.1ms preprocess, 949.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.3ms\n",
      "Speed: 5.4ms preprocess, 948.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.4ms\n",
      "Speed: 7.2ms preprocess, 945.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 920.9ms\n",
      "Speed: 5.1ms preprocess, 920.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 978.0ms\n",
      "Speed: 5.1ms preprocess, 978.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 940.8ms\n",
      "Speed: 5.5ms preprocess, 940.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 938.0ms\n",
      "Speed: 5.1ms preprocess, 938.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 937.9ms\n",
      "Speed: 5.2ms preprocess, 937.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.5ms\n",
      "Speed: 5.2ms preprocess, 947.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 960.3ms\n",
      "Speed: 5.2ms preprocess, 960.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 987.5ms\n",
      "Speed: 6.2ms preprocess, 987.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 931.4ms\n",
      "Speed: 5.2ms preprocess, 931.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 961.1ms\n",
      "Speed: 5.1ms preprocess, 961.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 925.5ms\n",
      "Speed: 5.1ms preprocess, 925.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.3ms\n",
      "Speed: 5.1ms preprocess, 955.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 928.2ms\n",
      "Speed: 5.2ms preprocess, 928.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.4ms\n",
      "Speed: 5.2ms preprocess, 956.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.8ms\n",
      "Speed: 5.2ms preprocess, 953.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 980.6ms\n",
      "Speed: 5.1ms preprocess, 980.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.1ms\n",
      "Speed: 5.2ms preprocess, 949.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 958.1ms\n",
      "Speed: 5.3ms preprocess, 958.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.0ms\n",
      "Speed: 5.1ms preprocess, 947.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.2ms\n",
      "Speed: 5.2ms preprocess, 956.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 982.8ms\n",
      "Speed: 5.4ms preprocess, 982.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.3ms\n",
      "Speed: 5.1ms preprocess, 948.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 954.3ms\n",
      "Speed: 5.0ms preprocess, 954.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.9ms\n",
      "Speed: 5.1ms preprocess, 945.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.7ms\n",
      "Speed: 5.2ms preprocess, 946.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.7ms\n",
      "Speed: 5.1ms preprocess, 955.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 960.7ms\n",
      "Speed: 5.2ms preprocess, 960.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.7ms\n",
      "Speed: 5.1ms preprocess, 948.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.0ms\n",
      "Speed: 5.2ms preprocess, 948.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.3ms\n",
      "Speed: 5.1ms preprocess, 948.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.4ms\n",
      "Speed: 5.3ms preprocess, 952.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.2ms\n",
      "Speed: 7.1ms preprocess, 956.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.8ms\n",
      "Speed: 5.0ms preprocess, 956.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.9ms\n",
      "Speed: 5.1ms preprocess, 955.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 958.5ms\n",
      "Speed: 5.4ms preprocess, 958.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 985.2ms\n",
      "Speed: 5.1ms preprocess, 985.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 963.2ms\n",
      "Speed: 5.0ms preprocess, 963.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 930.7ms\n",
      "Speed: 5.3ms preprocess, 930.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 954.9ms\n",
      "Speed: 5.3ms preprocess, 954.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.7ms\n",
      "Speed: 6.6ms preprocess, 955.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 964.1ms\n",
      "Speed: 5.7ms preprocess, 964.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 963.1ms\n",
      "Speed: 5.3ms preprocess, 963.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 965.0ms\n",
      "Speed: 5.3ms preprocess, 965.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 958.9ms\n",
      "Speed: 5.1ms preprocess, 958.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 994.8ms\n",
      "Speed: 5.1ms preprocess, 994.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 940.4ms\n",
      "Speed: 5.3ms preprocess, 940.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 957.6ms\n",
      "Speed: 5.4ms preprocess, 957.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 961.7ms\n",
      "Speed: 5.2ms preprocess, 961.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 989.7ms\n",
      "Speed: 5.2ms preprocess, 989.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 923.8ms\n",
      "Speed: 5.2ms preprocess, 923.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.1ms\n",
      "Speed: 5.2ms preprocess, 950.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.1ms\n",
      "Speed: 5.5ms preprocess, 946.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 963.7ms\n",
      "Speed: 5.1ms preprocess, 963.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 949.2ms\n",
      "Speed: 5.3ms preprocess, 949.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 977.6ms\n",
      "Speed: 5.2ms preprocess, 977.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 915.2ms\n",
      "Speed: 5.2ms preprocess, 915.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.5ms\n",
      "Speed: 5.0ms preprocess, 950.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 941.8ms\n",
      "Speed: 5.2ms preprocess, 941.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 945.7ms\n",
      "Speed: 5.1ms preprocess, 945.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.4ms\n",
      "Speed: 5.0ms preprocess, 955.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.1ms\n",
      "Speed: 5.0ms preprocess, 950.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 958.3ms\n",
      "Speed: 6.3ms preprocess, 958.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 950.7ms\n",
      "Speed: 7.3ms preprocess, 950.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 946.5ms\n",
      "Speed: 5.2ms preprocess, 946.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 947.9ms\n",
      "Speed: 5.1ms preprocess, 947.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.7ms\n",
      "Speed: 5.1ms preprocess, 948.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 944.3ms\n",
      "Speed: 5.3ms preprocess, 944.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 976.4ms\n",
      "Speed: 5.4ms preprocess, 976.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 971.5ms\n",
      "Speed: 5.2ms preprocess, 971.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 960.3ms\n",
      "Speed: 5.1ms preprocess, 960.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 955.8ms\n",
      "Speed: 5.3ms preprocess, 955.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 964.6ms\n",
      "Speed: 6.4ms preprocess, 964.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 1006.4ms\n",
      "Speed: 5.2ms preprocess, 1006.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 931.3ms\n",
      "Speed: 5.3ms preprocess, 931.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 961.4ms\n",
      "Speed: 5.2ms preprocess, 961.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 961.3ms\n",
      "Speed: 5.3ms preprocess, 961.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 1001.5ms\n",
      "Speed: 5.1ms preprocess, 1001.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 925.4ms\n",
      "Speed: 5.1ms preprocess, 925.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 972.9ms\n",
      "Speed: 5.1ms preprocess, 972.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 927.0ms\n",
      "Speed: 5.3ms preprocess, 927.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 948.5ms\n",
      "Speed: 5.1ms preprocess, 948.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 954.8ms\n",
      "Speed: 5.0ms preprocess, 954.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 951.8ms\n",
      "Speed: 5.2ms preprocess, 951.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 956.8ms\n",
      "Speed: 5.1ms preprocess, 956.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 953.2ms\n",
      "Speed: 5.0ms preprocess, 953.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 1010.0ms\n",
      "Speed: 5.1ms preprocess, 1010.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 958.4ms\n",
      "Speed: 5.2ms preprocess, 958.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 952.0ms\n",
      "Speed: 9.2ms preprocess, 952.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "0: 1024x1024 (no detections), 1181.5ms\n",
      "Speed: 81.2ms preprocess, 1181.5ms inference, 39.3ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "# output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "# c = 0\n",
    "# pdf_file_path = \"combined_images.pdf\"\n",
    "\n",
    "# # model = YOLO('/home/rshah133/bcd/v8n_1024/runs/detect/checkpoint/weights/best.pt')\n",
    "# model = model.cpu()\n",
    "# target_layers = [model.model.model[-4]]\n",
    "# cam = EigenCAM(model, target_layers, task='od')\n",
    "\n",
    "\n",
    "# with PdfPages(pdf_file_path) as pdf:\n",
    "#     for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "#         label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "#         pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "        \n",
    "#         img = cv2.resize(pred_img, (640, 640))\n",
    "#         rgb_img = img.copy()\n",
    "#         img = np.float32(img) / 255\n",
    "        \n",
    "#         grayscale_cam = cam(rgb_img)[0, :, :]\n",
    "        \n",
    "#         grayscale_cam_resized = cv2.resize(grayscale_cam, (img.shape[1], img.shape[0]))\n",
    "#         cam_image = show_cam_on_image(img, grayscale_cam_resized, use_rgb=True)\n",
    "        \n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(16, 6))\n",
    "#         axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[0].set_title('Ground Truth')\n",
    "#         axs[0].axis('off')\n",
    "#         axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[1].set_title('Prediction')\n",
    "#         axs[1].axis('off')\n",
    "#         axs[2].imshow(cv2.cvtColor(cam_image, cv2.COLOR_BGR2RGB))\n",
    "#         axs[2].set_title('EigenCAM Explainable AI')\n",
    "#         axs[2].axis('off')\n",
    "        \n",
    "#         c+=1\n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "# print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "\n",
    "# output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "# output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "# pdf_file_path = \"combined_images.pdf\"\n",
    "# with PdfPages(pdf_file_path) as pdf:\n",
    "#     for label_file, pred_file in zip(output_labels_file_names[:5], output_pred_file_names[:5]):\n",
    "#         label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "#         pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#         fig.suptitle(f\"Image: {label_file}\", fontsize=12)\n",
    "#         axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[0].set_title('Ground Truth')\n",
    "#         axs[0].axis('off')\n",
    "#         axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[1].set_title('Prediction')\n",
    "#         axs[1].axis('off')\n",
    "#         plt.tight_layout()\n",
    "#         c += 1\n",
    "        \n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)\n",
    "\n",
    "# print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
