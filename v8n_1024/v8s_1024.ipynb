{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5947e30b",
   "metadata": {},
   "source": [
    "Please install the necessary libraries using your terminal/shell in your env before running the code. You can check all the libraries mentioned in the next code block. To install any library you can use either one of the code mentioned below\n",
    "\n",
    "pip install library_name\n",
    "\n",
    "pip3 install library_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_name = { 0: 'Mass',\n",
    "1: 'Spiculation',\n",
    "2: 'Suspicious Calcification',\n",
    "3: 'Architectural Distortion',\n",
    "4: 'Asymmetry',\n",
    "5: 'Focal Asymmetry',\n",
    "6: 'Skin Thickening',\n",
    "7: 'Global Asymmetry',\n",
    "8: 'Suspicious Lymph Node',\n",
    "9: 'Skin Retraction',\n",
    "10: 'Nipple Retraction'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    0: (255, 0, 0),      # Red\n",
    "    1: (0, 255, 0),      # Green\n",
    "    2: (0, 0, 255),      # Blue\n",
    "    3: (255, 255, 0),    # Yellow\n",
    "    4: (255, 165, 0),    # Orange\n",
    "    5: (128, 0, 128),    # Purple\n",
    "    6: (0, 255, 255),    # Cyan\n",
    "    7: (255, 192, 203),  # Pink\n",
    "    8: (128, 128, 0),    # Olive\n",
    "    9: (0, 0, 0),        # Black\n",
    "    10: (169, 169, 169)  # Dark Grey\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedd37b",
   "metadata": {},
   "source": [
    "Mention dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a4ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /home/rshah133/bcd/dataset/split_1/train/labels.cache\n",
      "Removed: /home/rshah133/bcd/dataset/split_1/val/labels.cache\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/rshah133/bcd/dataset.yaml\"\n",
    "\n",
    "def remove_cache_files(directory):\n",
    "    cache_files = glob.glob(os.path.join(directory, \"*.cache\"))\n",
    "    for cache_file in cache_files:\n",
    "        os.remove(cache_file)\n",
    "        print(f\"Removed: {cache_file}\")\n",
    "        \n",
    "with open(path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c41e18",
   "metadata": {},
   "source": [
    "Change the model and hyperparameters.\n",
    "\n",
    "* Epochs = keep minimum 200\n",
    "* imgsz = change acc to your model assigned\n",
    "* patience = number of epochs model will check for accuracy improvement and then stop if accuracy is not improving\n",
    "* set device = [0,1] if you have 2 GPUs requested and device = 0 if only 1 GPU/CPU\n",
    "* save = True, this will help you save the model checkpoints on its own \n",
    "* save_period = 10, this is the number of epochs after which model will save the checkpoints\n",
    "* resume = True, if kernel crashes, model will continue training from the previous checkpoint\n",
    "* iou = keep iou between 0.5-0.7 and check for best metrics (hyperparamter toplay with)\n",
    "* optimzer  = AdamW is the best for our model from what I have noticed. you can experiment if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf44d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.68 ðŸš€ Python-3.11.6 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "                                                      CUDA:1 (NVIDIA A100-SXM4-80GB, 81158MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=/home/rshah133/bcd/dataset.yaml, epochs=200, time=None, patience=25, batch=10, imgsz=1024, save=True, save_period=10, cache=False, device=[0, 1], workers=8, project=None, name=checkpoint, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=None, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737974386.636304 1878247 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737974386.639196 1878247 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2120305  ultralytics.nn.modules.head.Detect           [11, [128, 256, 512]]         \n",
      "YOLOv8s summary: 225 layers, 11,139,857 parameters, 11,139,841 gradients, 28.7 GFLOPs\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: '.nfs00000001bf29df6600000445'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8s.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdamW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/engine/trainer.py:197\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Command\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m cmd, file \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_ddp_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDDP:\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m debug command \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ultralytics/utils/dist.py:61\u001b[0m, in \u001b[0;36mgenerate_ddp_command\u001b[0;34m(world_size, trainer)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m  \u001b[38;5;66;03m# noqa local import to avoid https://github.com/Lightning-AI/lightning/issues/15218\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mresume:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# remove the save_dir\u001b[39;00m\n\u001b[1;32m     62\u001b[0m file \u001b[38;5;241m=\u001b[39m generate_ddp_file(trainer)\n\u001b[1;32m     63\u001b[0m dist_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.run\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_9 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.launch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/packages/apps/jupyter/2023-10-09/lib/python3.11/shutil.py:732\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(fd)):\n\u001b[0;32m--> 732\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(fd)\n",
      "File \u001b[0;32m/packages/apps/jupyter/2023-10-09/lib/python3.11/shutil.py:683\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    681\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(entry\u001b[38;5;241m.\u001b[39mname, dir_fd\u001b[38;5;241m=\u001b[39mtopfd)\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/apps/jupyter/2023-10-09/lib/python3.11/shutil.py:681\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopfd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '.nfs00000001bf29df6600000445'"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8s.yaml')\n",
    "results = model.train(data = path, epochs = 200, imgsz = 1024, batch = 10, name = 'checkpoint', device = [0,1], patience = 25, save = True, save_period = 10, exist_ok = True, resume = True, iou = 0.5, optimizer = 'AdamW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d439060",
   "metadata": {},
   "source": [
    "Implemented Tensorboard. Code will redirect you to a link which should be opened in **Google Chrome** if nothing is getting displayed on safari.  You can choose not to run this code block if you want to not see the dashboard and save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe087fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill 1869322\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/detect/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae2a47",
   "metadata": {},
   "source": [
    "Mention test_dataset.yaml file path and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/rshah133/bcd/test_dataset.yaml\"\n",
    "\n",
    "with open(path, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "remove_cache_files(os.path.dirname(data_loaded['train']))\n",
    "remove_cache_files(os.path.dirname(data_loaded['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7a724",
   "metadata": {},
   "source": [
    "Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907270",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_file = 'prediction_progress.json'\n",
    "\n",
    "def save_progress(current_index):\n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump({'last_processed': current_index}, f)\n",
    "\n",
    "def load_progress():\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            return json.load(f)['last_processed']\n",
    "    return 0\n",
    "\n",
    "# Load model\n",
    "best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "\n",
    "if isinstance(data_loaded['val'], str):\n",
    "    val_path = Path(data_loaded['val'])\n",
    "    test_img_path = list(val_path.rglob('*.[jp][pn][gf]'))\n",
    "    test_img_path = [str(p) for p in test_img_path]\n",
    "else:\n",
    "    test_img_path = list(data_loaded['val'])\n",
    "\n",
    "start_index = load_progress()\n",
    "\n",
    "chunk_size = 48  # Adjust based on your available memory\n",
    "for i in range(start_index, len(test_img_path), chunk_size):\n",
    "    chunk_end = min(i + chunk_size, len(test_img_path))\n",
    "    current_chunk = test_img_path[i:chunk_end]\n",
    "    \n",
    "    try:\n",
    "        results = best_model.predict(source = current_chunk, save = True, save_txt = True, conf = 0.10, batch = chunk_size//4, stream = True)\n",
    "        \n",
    "        # code for post - processing results for later\n",
    "        for r in results:\n",
    "            pass  \n",
    "            \n",
    "        save_progress(chunk_end)\n",
    "        \n",
    "    except Exception as e:\n",
    "        save_progress(i)\n",
    "        print(f\"Prediction stopped at image {i}. Progress saved.\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92095830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = YOLO('runs/detect/checkpoint/weights/best.pt')\n",
    "# test_img_path = data_loaded['val']\n",
    "# results = best_model.predict(source = test_img_path, save = True,  save_txt = True,  conf = 0.10, batch = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150e326",
   "metadata": {},
   "source": [
    "Run this cell as it is and take screenshot of the output. This code is for calculating the metrics for test data\n",
    "\n",
    "u can play with conf keep between 0.05-0.2. lower value means it predicts more but with less accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_model.val(data = path, conf = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1198cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_dirs():\n",
    "    base_dir = \"runs/detect\"\n",
    "    # Get all predict directories\n",
    "    predict_dirs = [d for d in os.listdir(base_dir) if d.startswith('predict')]\n",
    "    # Sort them numerically (predict1, predict2, etc.)\n",
    "    predict_dirs.sort(key=lambda x: int(x.replace('predict', '')) if x != 'predict' else 0)\n",
    "    \n",
    "    return f\"{base_dir}/{predict_dirs[-1]}\"\n",
    "\n",
    "# Use the function to get all prediction directories\n",
    "predictions_dir = get_prediction_dirs()\n",
    "predictions_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104f47",
   "metadata": {},
   "source": [
    "Run this cell as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e871-b0d0-4b1a-a837-651b772103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = data_loaded['val']\n",
    "test_labels_dir = os.path.join(os.path.dirname(data_loaded['val']), 'labels')\n",
    "\n",
    "output_labels_dir = \"results/labels\"  # Directory to save ground truth images\n",
    "output_pred_dir = \"results/predictions\"  # Directory to save predicted images\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_pred_dir, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO format labels\n",
    "def read_yolo_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "            confidence = float(parts[5]) if len(parts) > 5 else None\n",
    "            labels.append((int(class_id), x_center, y_center, width, height, confidence))\n",
    "    return labels\n",
    "\n",
    "# Function to draw bounding boxes on images\n",
    "def draw_boxes(image, boxes):\n",
    "    h, w, _ = image.shape\n",
    "    for box in boxes:\n",
    "        class_id, x_center, y_center, width, height, confidence = box\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        x_max = int((x_center + width / 2) * w)\n",
    "        y_max = int((y_center + height / 2) * h)\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color_dict[class_id], 2)\n",
    "    return image\n",
    "\n",
    "# Loop through each image\n",
    "for image_file in os.listdir(test_images_dir):\n",
    "    if image_file.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        image_path = os.path.join(test_images_dir, image_file)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading {image_file}\")\n",
    "            continue\n",
    "\n",
    "        # Read ground truth labels\n",
    "        ground_truth_file = os.path.join(test_labels_dir, f\"{base_name}.txt\")\n",
    "        ground_truth_boxes = read_yolo_labels(ground_truth_file) if os.path.exists(ground_truth_file) else []\n",
    "\n",
    "        # Read prediction labels\n",
    "        prediction_file = os.path.join(predictions_dir, f\"{base_name}.txt\")\n",
    "        prediction_boxes = read_yolo_labels(prediction_file) if os.path.exists(prediction_file) else []\n",
    "\n",
    "        # Draw ground truth (green) and predictions (blue)\n",
    "        image_with_boxes_gt = draw_boxes(image.copy(), ground_truth_boxes)\n",
    "        image_with_boxes_pt = draw_boxes(image.copy(), prediction_boxes)\n",
    "\n",
    "        # Save annotated image\n",
    "        gt_output_path = os.path.join(output_labels_dir, image_file)\n",
    "        cv2.imwrite(gt_output_path, image_with_boxes_gt)\n",
    "\n",
    "        pt_output_path = os.path.join(output_pred_dir, image_file)\n",
    "        cv2.imwrite(pt_output_path, image_with_boxes_pt)\n",
    "\n",
    "print(\"Done saving the predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504c186",
   "metadata": {},
   "source": [
    "Code to plot images in a single pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "\n",
    "# output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "# output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "# pdf_file_path = \"combined_images.pdf\"\n",
    "# with PdfPages(pdf_file_path) as pdf:\n",
    "#     for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "#         label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "#         pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "\n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#         fig.suptitle(f\"Image: {label_file}\", fontsize=12)\n",
    "#         axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[0].set_title('Ground Truth')\n",
    "#         axs[0].axis('off')\n",
    "#         axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "#         axs[1].set_title('Prediction')\n",
    "#         axs[1].axis('off')\n",
    "#         plt.tight_layout()\n",
    "#         c += 1\n",
    "        \n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)\n",
    "\n",
    "# print(f\"{c} prediction images saved in {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34838ae9",
   "metadata": {},
   "source": [
    "This code block will display ground truth and predictions one by one in the notebook itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# output_labels_file_names = sorted(os.listdir(output_labels_dir))\n",
    "# output_pred_file_names = sorted(os.listdir(output_pred_dir))\n",
    "\n",
    "# for label_file, pred_file in zip(output_labels_file_names, output_pred_file_names):\n",
    "#     label_img = cv2.imread(os.path.join(output_labels_dir, label_file))\n",
    "#     pred_img = cv2.imread(os.path.join(output_pred_dir, pred_file))\n",
    "    \n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "#     axs[0].imshow(cv2.cvtColor(label_img, cv2.COLOR_BGR2RGB))\n",
    "#     axs[0].set_title('Ground Truth')\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].imshow(cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))\n",
    "#     axs[1].set_title('Prediction')\n",
    "#     axs[1].axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
